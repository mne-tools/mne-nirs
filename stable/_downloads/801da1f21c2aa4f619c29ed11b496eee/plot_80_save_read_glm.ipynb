{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Save and load GLM results\n\nThis is an example of how to save and load\nfunctional near-infrared spectroscopy (fNIRS)\nGLM results from analysis in MNE-NIRS.\nAs computation can be expensive and time consuming it can be useful\nto store computed results to disk, so that you can query the results later.\nFor example, to remake a figure or answer a new scientific question.\n\nFor a description of the analysis in this tutorial see the\n`MNE-NIRS individual GLM tutorial <tut-fnirs-hrf>` and\n`MNE-NIRS group GLM tutorial <tut-fnirs-group>`.\nThis tutorial will simply focus on saving and loading data.\n\nThe data used in this example is available\n[at this location](https://github.com/rob-luke/BIDS-NIRS-Tapping).\nIt is a finger tapping example and is briefly described below.\nThe dataset contains 5 participants.\nThe example dataset is in\n[BIDS](https://bids.neuroimaging.io)\nformat and therefore already contains\ninformation about triggers, condition names, etc.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>This tutorial uses data stored using\n   [the BIDS format](https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/11-near-infrared-spectroscopy.html)\n   :footcite:p:`luke2023bids`.\n\n   MNE-Python allows you to process fNIRS data that is not in BIDS format.\n   Simply modify the ``read_raw_`` function to match your data type.\n   See `data importing tutorial <tut-importing-fnirs-data>` to learn how\n   to use your data with MNE-Python.</p></div>\n   :depth: 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Robert Luke <mail@robertluke.net>\n#\n# License: BSD (3-clause)\n\n# Import common libraries\nfrom os.path import join\nimport pandas as pd\n\n# Import MNE functions\nfrom mne.preprocessing.nirs import optical_density, beer_lambert_law\n\n# Import MNE-NIRS functions\nfrom mne_nirs.statistics import run_glm\nfrom mne_nirs.experimental_design import make_first_level_design_matrix\nfrom mne_nirs.statistics import read_glm\nfrom mne_nirs.datasets import fnirs_motor_group\n\n# Import MNE-BIDS processing\nfrom mne_bids import BIDSPath, read_raw_bids, get_entity_vals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up directories\n\nFirst we will define where the raw data is stored. We will analyse a\nBIDS dataset, note that the BIDS specification for NIRS data is still\nunder development and you will need to install the development branch\nas described above.\n\nWe first define the root directory of our dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "root = fnirs_motor_group.data_path()\nprint(root)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And as we are using MNE-BIDS we can create a BIDSPath.\nThis helps to handle all the path wrangling.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = BIDSPath(root=root, task=\"tapping\")\nprint(dataset.directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For example we can automatically query the subjects, tasks, and sessions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "subjects = get_entity_vals(root, 'subject')\nprint(subjects)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But for this example we will only process the first two subjects\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "subjects = subjects[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define individual analysis\n\nFirst we define the analysis that will be applied to each file.\nThis is a GLM analysis as described in the\n`individual GLM tutorial <tut-fnirs-hrf>`,\nso this example will skim over the individual level details.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def individual_analysis(bids_path):\n\n    raw_intensity = read_raw_bids(bids_path=bids_path, verbose=False)\n    # Delete annotation labeled 15, as these just signify the start and end of experiment.\n    raw_intensity.annotations.delete(raw_intensity.annotations.description == '15.0')\n    raw_intensity.pick(picks=range(20)).crop(200).resample(0.3)  # Reduce load\n    raw_haemo = beer_lambert_law(optical_density(raw_intensity), ppf=0.1)\n    design_matrix = make_first_level_design_matrix(raw_haemo)\n    glm_est = run_glm(raw_haemo, design_matrix)\n\n    return glm_est"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run analysis and save to disk\n\nNext we loop through the five measurements and run the individual analysis\non each. We will then save the GLM results to disk as ``.h5`` files.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for sub in subjects:\n\n    # Create path to file based on experiment info\n    data_path = dataset.update(subject=sub,\n                               datatype=\"nirs\",\n                               suffix=\"nirs\",\n                               extension=\".snirf\")\n\n    # Analyse data and glm results\n    glm = individual_analysis(data_path)\n\n    # Next we create a location to store the results.\n    # In BIDS fashion we will store this in a subdirectory called derivatives.\n    # And we can use the BIDSPath type from above to handle the path details.\n\n    save_path = dataset.copy().update(\n        root=join(root, \"derivatives\"),\n        datatype=\"nirs\", suffix=\"glm\", extension=\".h5\",check=False)\n    # Ensure the folder exists, and make it if not.\n    save_path.fpath.parent.mkdir(exist_ok=True, parents=True)\n\n    # Finally we save the results to disk as a hdf5 file\n    glm.save(save_path.fpath, overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reload results and extract summary statistics\n\nNext we loop through the five measurements and reload all the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create a dataframe to store results\ndf = pd.DataFrame()\n\nfor sub in subjects:\n\n    # Point to the correct subject\n    save_path = save_path.update(subject=sub)\n\n    # Read the data\n    results = read_glm(save_path.fpath)\n\n    # Extract results from data as dataframe\n    individual_results = results.to_dataframe()\n\n    # Indicate the subject ID\n    individual_results[\"ID\"] = sub\n\n    # Append individual results to larger dataframe\n    df = pd.concat([df, individual_results], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View the resulting dataframe\n\nFinally we can view the resulting dataframe which contains data from all\nsubjects.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}