{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Utilising Auxiliary Data\n\nIn this example we demonstrate how to load\nauxiliary data from a SNIRF file and include it in\nthe design matrix for incorporating with your GLM\nanalysis.\n\nThis example builds on the\n`GLM tutorial <tut-fnirs-hrf>`.\nAs such, we will not explain the GLM procedure in this\nexample and refer readers to the detailed description above.\nInstead, we focus on extracting the auxiliary data and how\nthis can be incorporated in to your analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_number = 2\n\n# Authors: Robert Luke <code@robertluke.net>\n#\n# License: BSD (3-clause)\n\nimport matplotlib.pyplot as plt\nimport mne\nimport numpy as np\nimport pandas as pd\nfrom nilearn.plotting import plot_design_matrix\n\nfrom mne_nirs.channels import get_long_channels, get_short_channels\nfrom mne_nirs.datasets.snirf_with_aux import data_path\nfrom mne_nirs.experimental_design import make_first_level_design_matrix\nfrom mne_nirs.io.snirf import read_snirf_aux_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import raw NIRS data\n\nFirst we import the raw data. A different dataset is used from\nthe previous GLM example that contains auxiliary data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fnirs_snirf_file = data_path()\nraw_intensity = mne.io.read_raw_snirf(fnirs_snirf_file).load_data()\nraw_intensity.resample(0.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clean up annotations before analysis\n\nNext we update the annotations by assigning names to each trigger ID.\nThen we crop the recording to the section containing our\nexperimental conditions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw_intensity.annotations.rename(\n    {\"1\": \"Control\", \"2\": \"Tapping_Left\", \"3\": \"Tapping_Right\"}\n)\nraw_intensity.annotations.delete(raw_intensity.annotations.description == \"15\")\nraw_intensity.annotations.set_durations(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocess NIRS data\nNext we convert the raw data to haemoglobin concentration.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw_od = mne.preprocessing.nirs.optical_density(raw_intensity)\nraw_haemo = mne.preprocessing.nirs.beer_lambert_law(raw_od, ppf=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then split the data in to\nshort channels which predominantly contain systemic responses and\nlong channels which have both neural and systemic contributions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "short_chs = get_short_channels(raw_haemo)\nraw_haemo = get_long_channels(raw_haemo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create design matrix\n\n.. sidebar:: Relevant literature\n\n   For further discussion on design matrices see\n   the Nilearn examples. Specifically the\n   [first level model example](http://nilearn.github.io/auto_examples/04_glm_first_level/plot_first_level_details.html).\n\nNext we create a model to fit our data to.\nThe model consists of various components to model different things we assume\ncontribute to the measured signal.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "design_matrix = make_first_level_design_matrix(\n    raw_haemo,\n    drift_model=\"cosine\",\n    high_pass=0.005,  # Must be specified per experiment\n    hrf_model=\"spm\",\n    stim_dur=5.0,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also add the mean of the short channels to the design matrix.\nIn theory these channels contain only systemic components, so including\nthem in the design matrix allows us to estimate the neural component\nrelated to each experimental condition\nuncontaminated by systemic effects.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "design_matrix[\"ShortHbO\"] = np.mean(\n    short_chs.copy().pick(picks=\"hbo\").get_data(), axis=0\n)\n\ndesign_matrix[\"ShortHbR\"] = np.mean(\n    short_chs.copy().pick(picks=\"hbr\").get_data(), axis=0\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can view the design matrix by printing the variable\nand we see that it includes the standard regressors, but does\nnot yet contain any auxiliary data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots(figsize=(10, 6), nrows=1, ncols=1)\nfig = plot_design_matrix(design_matrix, ax=ax1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load auxiliary data\n\nThe design matrix is a pandas data frame. As such,\nwe wish to load the auxiliary data in the same format.\nThe following function will load the SNIRF file and extract\nthe auxiliary data. The auxiliary data can be sampled at a\ndifferent rate to the raw fNIRS data, so this function will\nconveniently resample the data to the same rate as the raw\nfNIRS data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "aux_df = read_snirf_aux_data(fnirs_snirf_file, raw_haemo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And you can verify the data looks reasonable by plotting\nindividual fields.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.plot(raw_haemo.times, aux_df[\"HR\"])\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Heart Rate (bpm)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Include auxiliary data in design matrix\n\nFinally we append the auxiliary data to the design matrix\nso that these can be included as regressors in a GLM analysis.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "design_matrix = pd.concat([design_matrix, aux_df], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And we can visually display the design matrix and verify\nthe data is included.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots(figsize=(10, 6), nrows=1, ncols=1)\nfig = plot_design_matrix(design_matrix, ax=ax1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\nWe have demonstrated how to load auxiliary data from a SNIRF\nfile. We illustrated how to include this data in your design matrix\nfor further GLM analysis. We do not go through a full GLM analysis,\ninstead the reader is directed to the dedicated `GLM tutorial <tut-fnirs-hrf>`.\nThe auxiliary data may need to be treated before being included in your analysis,\nfor example you may need to normalise before inclusion in statistical analysis etc,\nbut this is beyond the scope of this tutorial.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}