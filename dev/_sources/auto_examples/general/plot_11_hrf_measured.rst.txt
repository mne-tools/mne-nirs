
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/general/plot_11_hrf_measured.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_general_plot_11_hrf_measured.py>`
        to download the full example code. or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_general_plot_11_hrf_measured.py:


.. _tut-fnirs-hrf:

GLM Analysis (Measured)
============================

In this example we analyse data from a real multichannel
functional near-infrared spectroscopy (fNIRS)
experiment (see :ref:`tut-fnirs-hrf-sim` for a simplified simulated
analysis). The experiment consists of three conditions:

1. tapping with the left hand,
2. tapping with the right hand,
3. a control condition where the participant does nothing.

We use a GLM analysis to examine the neural activity associated with
the different tapping conditions.
An alternative epoching style analysis on the same data can be
viewed in the
:ref:`waveform analysis example <tut-fnirs-processing>`.
See
`Luke et al (2021) <https://www.spiedigitallibrary.org/journals/neurophotonics/volume-8/issue-2/025008/Analysis-methods-for-measuring-passive-auditory-fNIRS-responses-generated-by/10.1117/1.NPh.8.2.025008.short>`__
for a comparison of the epoching and GLM approaches.

This GLM analysis is a wrapper over the excellent
`Nilearn GLM <http://nilearn.github.io/modules/reference.html#module-nilearn.glm>`__.

.. GENERATED FROM PYTHON SOURCE LINES 28-46

.. code-block:: Python

    # sphinx_gallery_thumbnail_number = 9

    # Authors: Robert Luke <mail@robertluke.net>
    #
    # License: BSD (3-clause)

    import os

    import matplotlib.pyplot as plt
    import mne
    import numpy as np
    from nilearn.plotting import plot_design_matrix

    import mne_nirs
    from mne_nirs.channels import get_long_channels, get_short_channels, picks_pair_to_idx
    from mne_nirs.experimental_design import make_first_level_design_matrix
    from mne_nirs.statistics import run_glm








.. GENERATED FROM PYTHON SOURCE LINES 47-66

Import raw NIRS data
--------------------

First we import the motor tapping data, these data are also
described and used in the
:ref:`MNE fNIRS tutorial <mne:tut-fnirs-processing>`

After reading the data we resample down to 1Hz
to meet github memory constraints.

.. note::

   Optodes were placed over the motor cortex using the standard NIRX motor
   montage, but with 8 short channels added (see their web page for details).
   To view the sensor locations run ``raw_intensity.plot_sensors()``.
   A sound was presented to indicate which hand the participant should tap.
   Participants tapped their thumb to their fingers for 5s.
   Conditions were presented in a random order with a randomised inter
   stimulus interval.

.. GENERATED FROM PYTHON SOURCE LINES 66-73

.. code-block:: Python


    fnirs_data_folder = mne.datasets.fnirs_motor.data_path()
    fnirs_raw_dir = os.path.join(fnirs_data_folder, "Participant-1")
    raw_intensity = mne.io.read_raw_nirx(fnirs_raw_dir).load_data()
    raw_intensity.resample(0.7)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Loading /home/circleci/mne_data/MNE-fNIRS-motor-data/Participant-1
    Reading 0 ... 23238  =      0.000 ...  2974.464 secs...


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <script type="text/javascript">
        // must be `var` (not `const`) because this can get embedded multiple times on a page
    var toggleVisibility = (className) => {

        const elements = document.querySelectorAll(`.${className}`);

        elements.forEach(element => {
            if (element.classList.contains("mne-repr-section-header")) {
                return  // Don't collapse the section header row
            }
            element.classList.toggle("mne-repr-collapsed");
        });

        // trigger caret to rotate
        var sel = `.mne-repr-section-header.${className} > th.mne-repr-section-toggle > button`;
        const button = document.querySelector(sel);
        button.classList.toggle("collapsed");

        // adjust tooltip
        sel = `tr.mne-repr-section-header.${className}`;
        const secHeadRow = document.querySelector(sel);
        secHeadRow.classList.toggle("collapsed");
        secHeadRow.title = secHeadRow.title === "Hide section" ? "Show section" : "Hide section";
    }
    </script>

    <style type="text/css">
        /*
    Styles in this section apply both to the sphinx-built website docs and to notebooks
    rendered in an IDE or in Jupyter. In our web docs, styles here are complemented by
    doc/_static/styles.css and other CSS files (e.g. from the sphinx theme, sphinx-gallery,
    or bootstrap). In IDEs/Jupyter, those style files are unavailable, so only the rules in
    this file apply (plus whatever default styling the IDE applies).
    */
    .mne-repr-table {
        display: inline;  /* prevent using full container width */
    }
    .mne-repr-table tr.mne-repr-section-header > th {
        padding-top: 1rem;
        text-align: left;
        vertical-align: middle;
    }
    .mne-repr-section-toggle > button {
        all: unset;
        display: block;
        height: 1rem;
        width: 1rem;
    }
    .mne-repr-section-toggle > button > svg {
        height: 60%;
    }

    /* transition (rotation) effects on the collapser button */
    .mne-repr-section-toggle > button.collapsed > svg {
        transition: 0.1s ease-out;
        transform: rotate(-90deg);
    }
    .mne-repr-section-toggle > button:not(.collapsed) > svg {
        transition: 0.1s ease-out;
        transform: rotate(0deg);
    }

    /* hide collapsed table rows */
    .mne-repr-collapsed {
        display: none;
    }


    @layer {
        /*
        Selectors in a `@layer` will always be lower-precedence than selectors outside the
        layer. So even though e.g. `div.output_html` is present in the sphinx-rendered
        website docs, the styles here won't take effect there as long as some other rule
        somewhere in the page's CSS targets the same element.

        In IDEs or Jupyter notebooks, though, the CSS files from the sphinx theme,
        sphinx-gallery, and bootstrap are unavailable, so these styles will apply.

        Notes:

        - the selector `.accordion-body` is for MNE Reports
        - the selector `.output_html` is for VSCode's notebook interface
        - the selector `.jp-RenderedHTML` is for Jupyter notebook
        - variables starting with `--theme-` are VSCode-specific.
        - variables starting with `--jp-` are Jupyter styles, *some of which* are also
          available in VSCode. Here we try the `--theme-` variable first, then fall back to
          the `--jp-` ones.
        */
        .mne-repr-table {
            --mne-toggle-color: var(--theme-foreground, var(--jp-ui-font-color1));
            --mne-button-bg-color: var(--theme-button-background, var(--jp-info-color0, var(--jp-content-link-color)));
            --mne-button-fg-color: var(--theme-button-foreground, var(--jp-ui-inverse-font-color0, var(--jp-editor-background)));
            --mne-button-hover-bg-color: var(--theme-button-hover-background, var(--jp-info-color1));
            --mne-button-radius: var(--jp-border-radius, 0.25rem);
        }
        /* chevron position/alignment; in VSCode it looks ok without adjusting */
        .accordion-body .mne-repr-section-toggle > button,
        .jp-RenderedHTML .mne-repr-section-toggle > button {
            padding: 0 0 45% 25% !important;
        }
        /* chevron color; MNE Report doesn't have light/dark mode */
        div.output_html .mne-repr-section-toggle > button > svg > path,
        .jp-RenderedHTML .mne-repr-section-toggle > button > svg > path {
            fill: var(--mne-toggle-color);
        }
        .accordion-body .mne-ch-names-btn,
        div.output_html .mne-ch-names-btn,
        .jp-RenderedHTML .mne-ch-names-btn {
            -webkit-border-radius: var(--mne-button-radius);
            -moz-border-radius: var(--mne-button-radius);
            border-radius: var(--mne-button-radius);
            border: none;
            background-image: none;
            background-color: var(--mne-button-bg-color);
            color: var(--mne-button-fg-color);
            font-size: inherit;
            min-width: 1.5rem;
            padding: 0.25rem;
            text-align: center;
            text-decoration: none;
        }
        .accordion-body .mne-ch-names-btn:hover,
        div.output_html .mne.ch-names-btn:hover,
        .jp-RenderedHTML .mne-ch-names-btn:hover {
            background-color: var(--mne-button-hover-bg-color);
            text-decoration: underline;
        }
        .accordion-body .mne-ch-names-btn:focus-visible,
        div.output_html .mne-ch-names-btn:focus-visible,
        .jp-RenderedHTML .mne-ch-names-btn:focus-visible {
            outline: 0.1875rem solid var(--mne-button-bg-color) !important;
            outline-offset: 0.1875rem !important;
        }
    }
    </style>



    <table class="table mne-repr-table">
    







    <tr class="mne-repr-section-header general-9f4180fa-163b-4e12-8ae3-3f3774b6380b"
         title="Hide section" 
        onclick="toggleVisibility('general-9f4180fa-163b-4e12-8ae3-3f3774b6380b')">
        <th class="mne-repr-section-toggle">
            <button >
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path d="M233.4 406.6c12.5 12.5 32.8 12.5 45.3 0l192-192c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L256 338.7 86.6 169.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l192 192z"/></svg>
            </button>
        </th>
        <th colspan="2">
            <strong>General</strong>
        </th>
    </tr>


    <tr class="repr-element general-9f4180fa-163b-4e12-8ae3-3f3774b6380b ">
        <td class="mne-repr-section-toggle"></td>
        <td>Filename(s)</td>
        <td>
        
            Participant-1
        
        
        </td>
    </tr>

    <tr class="repr-element general-9f4180fa-163b-4e12-8ae3-3f3774b6380b ">
        <td class="mne-repr-section-toggle"></td>
        <td>MNE object type</td>
        <td>RawNIRX</td>
    </tr>
    <tr class="repr-element general-9f4180fa-163b-4e12-8ae3-3f3774b6380b ">
        <td class="mne-repr-section-toggle"></td>
        <td>Measurement date</td>
    
        <td>2019-11-02 at 13:16:16 UTC</td>
    
    </tr>
    <tr class="repr-element general-9f4180fa-163b-4e12-8ae3-3f3774b6380b ">
        <td class="mne-repr-section-toggle"></td>
        <td>Participant</td>
    
    
        <td>P1</td>
    
    
    </tr>
    <tr class="repr-element general-9f4180fa-163b-4e12-8ae3-3f3774b6380b ">
        <td class="mne-repr-section-toggle"></td>
        <td>Experimenter</td>
    
        <td>Unknown</td>
    
    </tr>
    







    <tr class="mne-repr-section-header acquisition-7b4a973e-e54d-4682-a581-3ba36be3baa5"
         title="Hide section" 
        onclick="toggleVisibility('acquisition-7b4a973e-e54d-4682-a581-3ba36be3baa5')">
        <th class="mne-repr-section-toggle">
            <button >
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path d="M233.4 406.6c12.5 12.5 32.8 12.5 45.3 0l192-192c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L256 338.7 86.6 169.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l192 192z"/></svg>
            </button>
        </th>
        <th colspan="2">
            <strong>Acquisition</strong>
        </th>
    </tr>


    <tr class="repr-element acquisition-7b4a973e-e54d-4682-a581-3ba36be3baa5 ">
        <td class="mne-repr-section-toggle"></td>
        <td>Duration</td>
        <td>00:49:35 (HH:MM:SS)</td>
    </tr>








    <tr class="repr-element acquisition-7b4a973e-e54d-4682-a581-3ba36be3baa5 ">
        <td class="mne-repr-section-toggle"></td>
        <td>Sampling frequency</td>
        <td>0.70 Hz</td>
    </tr>


    <tr class="repr-element acquisition-7b4a973e-e54d-4682-a581-3ba36be3baa5 ">
        <td class="mne-repr-section-toggle"></td>
        <td>Time points</td>
        <td>2,082</td>
    </tr>


    







    <tr class="mne-repr-section-header channels-36a5c04a-82be-4b2a-8290-9e39c0729637"
         title="Hide section" 
        onclick="toggleVisibility('channels-36a5c04a-82be-4b2a-8290-9e39c0729637')">
        <th class="mne-repr-section-toggle">
            <button >
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path d="M233.4 406.6c12.5 12.5 32.8 12.5 45.3 0l192-192c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L256 338.7 86.6 169.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l192 192z"/></svg>
            </button>
        </th>
        <th colspan="2">
            <strong>Channels</strong>
        </th>
    </tr>


    
    <tr class="repr-element channels-36a5c04a-82be-4b2a-8290-9e39c0729637 ">
        <td class="mne-repr-section-toggle"></td>
        <td>fNIRS (CW amplitude)</td>
        <td>
            <button class="mne-ch-names-btn sd-sphinx-override sd-btn sd-btn-info sd-text-wrap sd-shadow-sm" onclick="alert('Good fNIRS (CW amplitude):\n\nS1_D1&nbsp;760, S1_D1&nbsp;850, S1_D2&nbsp;760, S1_D2&nbsp;850, S1_D3&nbsp;760, S1_D3&nbsp;850, S1_D9&nbsp;760, S1_D9&nbsp;850, S2_D1&nbsp;760, S2_D1&nbsp;850, S2_D3&nbsp;760, S2_D3&nbsp;850, S2_D4&nbsp;760, S2_D4&nbsp;850, S2_D10&nbsp;760, S2_D10&nbsp;850, S3_D2&nbsp;760, S3_D2&nbsp;850, S3_D3&nbsp;760, S3_D3&nbsp;850, S3_D11&nbsp;760, S3_D11&nbsp;850, S4_D3&nbsp;760, S4_D3&nbsp;850, S4_D4&nbsp;760, S4_D4&nbsp;850, S4_D12&nbsp;760, S4_D12&nbsp;850, S5_D5&nbsp;760, S5_D5&nbsp;850, S5_D6&nbsp;760, S5_D6&nbsp;850, S5_D7&nbsp;760, S5_D7&nbsp;850, S5_D13&nbsp;760, S5_D13&nbsp;850, S6_D5&nbsp;760, S6_D5&nbsp;850, S6_D7&nbsp;760, S6_D7&nbsp;850, S6_D8&nbsp;760, S6_D8&nbsp;850, S6_D14&nbsp;760, S6_D14&nbsp;850, S7_D6&nbsp;760, S7_D6&nbsp;850, S7_D7&nbsp;760, S7_D7&nbsp;850, S7_D15&nbsp;760, S7_D15&nbsp;850, S8_D7&nbsp;760, S8_D7&nbsp;850, S8_D8&nbsp;760, S8_D8&nbsp;850, S8_D16&nbsp;760, S8_D16&nbsp;850')" title="(Click to open in popup)&#13;&#13;S1_D1&nbsp;760, S1_D1&nbsp;850, S1_D2&nbsp;760, S1_D2&nbsp;850, S1_D3&nbsp;760, S1_D3&nbsp;850, S1_D9&nbsp;760, S1_D9&nbsp;850, S2_D1&nbsp;760, S2_D1&nbsp;850, S2_D3&nbsp;760, S2_D3&nbsp;850, S2_D4&nbsp;760, S2_D4&nbsp;850, S2_D10&nbsp;760, S2_D10&nbsp;850, S3_D2&nbsp;760, S3_D2&nbsp;850, S3_D3&nbsp;760, S3_D3&nbsp;850, S3_D11&nbsp;760, S3_D11&nbsp;850, S4_D3&nbsp;760, S4_D3&nbsp;850, S4_D4&nbsp;760, S4_D4&nbsp;850, S4_D12&nbsp;760, S4_D12&nbsp;850, S5_D5&nbsp;760, S5_D5&nbsp;850, S5_D6&nbsp;760, S5_D6&nbsp;850, S5_D7&nbsp;760, S5_D7&nbsp;850, S5_D13&nbsp;760, S5_D13&nbsp;850, S6_D5&nbsp;760, S6_D5&nbsp;850, S6_D7&nbsp;760, S6_D7&nbsp;850, S6_D8&nbsp;760, S6_D8&nbsp;850, S6_D14&nbsp;760, S6_D14&nbsp;850, S7_D6&nbsp;760, S7_D6&nbsp;850, S7_D7&nbsp;760, S7_D7&nbsp;850, S7_D15&nbsp;760, S7_D15&nbsp;850, S8_D7&nbsp;760, S8_D7&nbsp;850, S8_D8&nbsp;760, S8_D8&nbsp;850, S8_D16&nbsp;760, S8_D16&nbsp;850">
                56
            </button>

        
        </td>
    </tr>


    <tr class="repr-element channels-36a5c04a-82be-4b2a-8290-9e39c0729637 ">
        <td class="mne-repr-section-toggle"></td>
        <td>Head & sensor digitization</td>
    
        <td>31 points</td>
    
    </tr>
    







    <tr class="mne-repr-section-header filters-855ca354-9a4a-40d7-9f55-9dc092b66515"
         title="Hide section" 
        onclick="toggleVisibility('filters-855ca354-9a4a-40d7-9f55-9dc092b66515')">
        <th class="mne-repr-section-toggle">
            <button >
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path d="M233.4 406.6c12.5 12.5 32.8 12.5 45.3 0l192-192c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L256 338.7 86.6 169.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l192 192z"/></svg>
            </button>
        </th>
        <th colspan="2">
            <strong>Filters</strong>
        </th>
    </tr>


    <tr class="repr-element filters-855ca354-9a4a-40d7-9f55-9dc092b66515 ">
        <td class="mne-repr-section-toggle"></td>
        <td>Highpass</td>
        <td>0.00 Hz</td>
    </tr>


    <tr class="repr-element filters-855ca354-9a4a-40d7-9f55-9dc092b66515 ">
        <td class="mne-repr-section-toggle"></td>
        <td>Lowpass</td>
        <td>0.35 Hz</td>
    </tr>


    </table>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 74-83

Clean up annotations before analysis
------------------------------------

Next we update the annotations by assigning names to each trigger ID.
Then we crop the recording to the section containing our
experimental conditions.

Because of limitations with ``nilearn``, we use ``'_'`` to separate conditions
rather than the standard ``'/'``.

.. GENERATED FROM PYTHON SOURCE LINES 83-90

.. code-block:: Python

    raw_intensity.annotations.rename(
        {"1.0": "Control", "2.0": "Tapping_Left", "3.0": "Tapping_Right"}
    )
    raw_intensity.annotations.delete(raw_intensity.annotations.description == "15.0")
    raw_intensity.annotations.set_durations(5)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Annotations | 90 segments: Control (30), Tapping_Left (30), Tapping_Right ...>



.. GENERATED FROM PYTHON SOURCE LINES 91-94

Preprocess NIRS data
--------------------
Next we convert the raw data to haemoglobin concentration.

.. GENERATED FROM PYTHON SOURCE LINES 94-99

.. code-block:: Python


    raw_od = mne.preprocessing.nirs.optical_density(raw_intensity)
    raw_haemo = mne.preprocessing.nirs.beer_lambert_law(raw_od, ppf=0.1)









.. GENERATED FROM PYTHON SOURCE LINES 100-109

.. sidebar:: Relevant literature

   Tachtsidis, Ilias, and Felix Scholkmann. "False positives and false
   negatives in functional near-infrared spectroscopy: issues, challenges,
   and the way forward." Neurophotonics 3.3 (2016): 031405.

We then split the data in to
short channels which predominantly contain systemic responses and
long channels which have both neural and systemic contributions.

.. GENERATED FROM PYTHON SOURCE LINES 110-115

.. code-block:: Python


    short_chs = get_short_channels(raw_haemo)
    raw_haemo = get_long_channels(raw_haemo)









.. GENERATED FROM PYTHON SOURCE LINES 116-125

View experiment events
----------------------

Next we examine the timing and order of events in this experiment.
There are several options for how to view event information.
The first option is to use MNE's plot events command.
Here each dot represents when an event started.
We observe that the order of conditions was randomised and the time between
events is also randomised.

.. GENERATED FROM PYTHON SOURCE LINES 125-130

.. code-block:: Python


    events, event_dict = mne.events_from_annotations(raw_haemo, verbose=False)
    mne.viz.plot_events(events, event_id=event_dict, sfreq=raw_haemo.info["sfreq"])





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_11_hrf_measured_001.png
   :alt: plot 11 hrf measured
   :srcset: /auto_examples/general/images/sphx_glr_plot_11_hrf_measured_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Figure size 640x480 with 1 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 131-134

The previous plot did not illustrate the duration that an event lasted for.
Alternatively, we can view the experiment using a boxcar plot, where the
line is raised for the duration of the stimulus/condition.

.. GENERATED FROM PYTHON SOURCE LINES 135-143

.. code-block:: Python


    s = mne_nirs.experimental_design.create_boxcar(raw_haemo)
    fig, ax = plt.subplots(figsize=(15, 6), constrained_layout=True)
    ax.plot(raw_haemo.times, s)
    ax.legend(["Control", "Left", "Right"], loc="upper right")
    ax.set_xlabel("Time (s)")





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_11_hrf_measured_002.png
   :alt: plot 11 hrf measured
   :srcset: /auto_examples/general/images/sphx_glr_plot_11_hrf_measured_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Used Annotations descriptions: [np.str_('Control'), np.str_('Tapping_Left'), np.str_('Tapping_Right')]

    Text(0.5, 18.167, 'Time (s)')



.. GENERATED FROM PYTHON SOURCE LINES 144-166

Create design matrix
--------------------

.. sidebar:: Relevant literature

   For further discussion on design matrices see
   the Nilearn examples. Specifically the
   `first level model example <http://nilearn.github.io/auto_examples/04_glm_first_level/plot_first_level_details.html>`__.

Next we create a model to fit our data to.
The model consists of various components to model different things we assume
contribute to the measured signal.
We model the expected neural response for each experimental condition
using the SPM haemodynamic response
function (HRF) combined with the known stimulus event times and durations
(as described above).
We also include a cosine drift model with components up to the high pass
parameter value. See the nilearn documentation for recommendations on setting
these values. In short, they suggest "The cutoff period (1/high_pass) should be
set as the longest period between two trials of the same condition multiplied by 2.
For instance, if the longest period is 32s, the high_pass frequency shall be
1/64 Hz ~ 0.016 Hz".

.. GENERATED FROM PYTHON SOURCE LINES 166-176

.. code-block:: Python


    design_matrix = make_first_level_design_matrix(
        raw_haemo,
        drift_model="cosine",
        high_pass=0.005,  # Must be specified per experiment
        hrf_model="spm",
        stim_dur=5.0,
    )









.. GENERATED FROM PYTHON SOURCE LINES 177-182

We also add the mean of the short channels to the design matrix.
In theory these channels contain only systemic components, so including
them in the design matrix allows us to estimate the neural component
related to each experimental condition
uncontaminated by systemic effects.

.. GENERATED FROM PYTHON SOURCE LINES 183-193

.. code-block:: Python


    design_matrix["ShortHbO"] = np.mean(
        short_chs.copy().pick(picks="hbo").get_data(), axis=0
    )

    design_matrix["ShortHbR"] = np.mean(
        short_chs.copy().pick(picks="hbr").get_data(), axis=0
    )









.. GENERATED FROM PYTHON SOURCE LINES 194-200

And we display a summary of the design matrix
using standard Nilearn reporting functions.
The first three columns represent the SPM HRF convolved with our stimulus
event information.
The next columns illustrate the drift and constant components.
The last columns illustrate the short channel signals.

.. GENERATED FROM PYTHON SOURCE LINES 201-206

.. code-block:: Python


    fig, ax1 = plt.subplots(figsize=(10, 6), constrained_layout=True)
    fig = plot_design_matrix(design_matrix, axes=ax1)





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_11_hrf_measured_003.png
   :alt: plot 11 hrf measured
   :srcset: /auto_examples/general/images/sphx_glr_plot_11_hrf_measured_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 207-225

Examine expected response
-------------------------

The matrices above can be a bit abstract as they encompase multiple
conditions and regressors.
Instead we can examine a single condition.
Here we observe the boxcar function for a single condition,
this illustrates when the stimulus was active.
We also view the expected neural response using the HRF specified above,
we observe that each time a stimulus is presented there is an expected
brain response that lags the stimulus onset and consists of a large positive
component followed by an undershoot.

In this example the second trigger (index 1) corresponds to the ``Tapping/Left``
condition in the design matrix, so we plot those below. In your data the mapping
may be different, so you may need to alter either the ``s`` index or condition
name. Note however, that this is just for visualisation and does not affect
the results below.

.. GENERATED FROM PYTHON SOURCE LINES 225-234

.. code-block:: Python


    fig, ax = plt.subplots(constrained_layout=True)
    s = mne_nirs.experimental_design.create_boxcar(raw_intensity, stim_dur=5.0)
    ax.plot(raw_intensity.times, s[:, 1])
    ax.plot(design_matrix["Tapping_Left"])
    ax.legend(["Stimulus", "Expected Response"])
    ax.set(xlim=(180, 300), xlabel="Time (s)", ylabel="Amplitude")





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_11_hrf_measured_004.png
   :alt: plot 11 hrf measured
   :srcset: /auto_examples/general/images/sphx_glr_plot_11_hrf_measured_004.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Used Annotations descriptions: [np.str_('Control'), np.str_('Tapping_Left'), np.str_('Tapping_Right')]

    [(180.0, 300.0), Text(0.5, 18.167, 'Time (s)'), Text(18.167, 0.5, 'Amplitude')]



.. GENERATED FROM PYTHON SOURCE LINES 235-247

Fit GLM to subset of data and estimate response for each experimental condition
-------------------------------------------------------------------------------

.. sidebar:: Relevant literature

   Huppert TJ. Commentary on the statistical properties of noise and its
   implication on general linear models in functional near-infrared
   spectroscopy. Neurophotonics. 2016;3(1)

We run a GLM fit for the data and experiment matrix.
First we analyse just the first two channels which correspond to HbO and HbR
of a single source detector pair.

.. GENERATED FROM PYTHON SOURCE LINES 248-252

.. code-block:: Python


    data_subset = raw_haemo.copy().pick(picks=range(2))
    glm_est = run_glm(data_subset, design_matrix)








.. GENERATED FROM PYTHON SOURCE LINES 253-256

This returns a GLM regression estimate for each channel.
This data is stored in a dedicated type.
You can view an overview of the estimates by addressing the variable:

.. GENERATED FROM PYTHON SOURCE LINES 257-260

.. code-block:: Python


    glm_est





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    GLM Results for 2 channels



.. GENERATED FROM PYTHON SOURCE LINES 261-266

As with other MNE types you can use the `pick` function.
To query the mean square error of a single channel you would call.

Note: as we wish to retain both channels for further the analysis below,
we operate on a copy to demonstrate this channel picking functionality.

.. GENERATED FROM PYTHON SOURCE LINES 267-270

.. code-block:: Python


    glm_est.copy().pick("S1_D1 hbr")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    GLM Results for 1 channels



.. GENERATED FROM PYTHON SOURCE LINES 271-276

Underlying the data for each channel is a standard
`Nilearn RegressionResults object <https://nilearn.github.io/modules/generated/nilearn.glm.RegressionResults.html>`_
object. These objects are rich with information that can be requested
from the object, for example to determine the mean square error of the
estimates for two channels you would call:

.. GENERATED FROM PYTHON SOURCE LINES 277-280

.. code-block:: Python


    glm_est.MSE()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    [np.float64(3.6359501281260776e-11), np.float64(9.48201077576092e-12)]



.. GENERATED FROM PYTHON SOURCE LINES 281-284

And we can chain the methods to quickly access required details.
For example, to determine the MSE for channel `S1` `D1` for the hbr type
you would call:

.. GENERATED FROM PYTHON SOURCE LINES 285-289

.. code-block:: Python


    glm_est.copy().pick("S1_D1 hbr").MSE()






.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    [np.float64(9.48201077576092e-12)]



.. GENERATED FROM PYTHON SOURCE LINES 290-295

Due to the richness of the objects we provide a function to
extract commonly used information and put it in a convenient dataframe/table.
Below this is demonstrated and then we just display the first 9 rows of the
table which correspond to the 9 components of the design matrix for the
first channel.

.. GENERATED FROM PYTHON SOURCE LINES 296-299

.. code-block:: Python


    glm_est.to_dataframe().head(9)






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th>variable</th>
          <th>Condition</th>
          <th>df</th>
          <th>mse</th>
          <th>p_value</th>
          <th>se</th>
          <th>t</th>
          <th>theta</th>
          <th>Source</th>
          <th>Detector</th>
          <th>Chroma</th>
          <th>Significant</th>
          <th>ch_name</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>Control</td>
          <td>35.0</td>
          <td>3.635950e-11</td>
          <td>5.703922e-01</td>
          <td>1.271854e-06</td>
          <td>0.572874</td>
          <td>7.286122e-07</td>
          <td>1</td>
          <td>1</td>
          <td>hbo</td>
          <td>False</td>
          <td>S1_D1 hbo</td>
        </tr>
        <tr>
          <th>1</th>
          <td>ShortHbO</td>
          <td>35.0</td>
          <td>3.635950e-11</td>
          <td>5.988346e-39</td>
          <td>1.253564e-02</td>
          <td>68.802806</td>
          <td>8.624875e-01</td>
          <td>1</td>
          <td>1</td>
          <td>hbo</td>
          <td>True</td>
          <td>S1_D1 hbo</td>
        </tr>
        <tr>
          <th>2</th>
          <td>ShortHbR</td>
          <td>35.0</td>
          <td>3.635950e-11</td>
          <td>2.051290e-19</td>
          <td>7.976514e-02</td>
          <td>-18.187656</td>
          <td>-1.450741e+00</td>
          <td>1</td>
          <td>1</td>
          <td>hbo</td>
          <td>True</td>
          <td>S1_D1 hbo</td>
        </tr>
        <tr>
          <th>3</th>
          <td>Tapping_Left</td>
          <td>35.0</td>
          <td>3.635950e-11</td>
          <td>8.464418e-06</td>
          <td>1.289978e-06</td>
          <td>5.211297</td>
          <td>6.722461e-06</td>
          <td>1</td>
          <td>1</td>
          <td>hbo</td>
          <td>True</td>
          <td>S1_D1 hbo</td>
        </tr>
        <tr>
          <th>4</th>
          <td>Tapping_Right</td>
          <td>35.0</td>
          <td>3.635950e-11</td>
          <td>7.547857e-16</td>
          <td>1.294997e-06</td>
          <td>13.935896</td>
          <td>1.804694e-05</td>
          <td>1</td>
          <td>1</td>
          <td>hbo</td>
          <td>True</td>
          <td>S1_D1 hbo</td>
        </tr>
        <tr>
          <th>5</th>
          <td>constant</td>
          <td>35.0</td>
          <td>3.635950e-11</td>
          <td>5.227182e-02</td>
          <td>2.943860e-07</td>
          <td>-2.009249</td>
          <td>-5.914949e-07</td>
          <td>1</td>
          <td>1</td>
          <td>hbo</td>
          <td>False</td>
          <td>S1_D1 hbo</td>
        </tr>
        <tr>
          <th>6</th>
          <td>drift_1</td>
          <td>35.0</td>
          <td>3.635950e-11</td>
          <td>6.333101e-25</td>
          <td>3.084314e-05</td>
          <td>26.818114</td>
          <td>8.271549e-04</td>
          <td>1</td>
          <td>1</td>
          <td>hbo</td>
          <td>True</td>
          <td>S1_D1 hbo</td>
        </tr>
        <tr>
          <th>7</th>
          <td>drift_10</td>
          <td>35.0</td>
          <td>3.635950e-11</td>
          <td>8.211815e-07</td>
          <td>1.215036e-05</td>
          <td>5.979676</td>
          <td>7.265522e-05</td>
          <td>1</td>
          <td>1</td>
          <td>hbo</td>
          <td>True</td>
          <td>S1_D1 hbo</td>
        </tr>
        <tr>
          <th>8</th>
          <td>drift_11</td>
          <td>35.0</td>
          <td>3.635950e-11</td>
          <td>4.069713e-01</td>
          <td>1.242152e-05</td>
          <td>0.839347</td>
          <td>1.042596e-05</td>
          <td>1</td>
          <td>1</td>
          <td>hbo</td>
          <td>False</td>
          <td>S1_D1 hbo</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 300-307

We then display the results using the scatter plot function.
Note that the control condition sits
around zero
and that the HbO is positive and larger than the HbR, this is to be expected.
Further, we note that for this channel the response to tapping on the
right hand is larger than the left. And the values are similar to what
is seen in the epoching tutorial.

.. GENERATED FROM PYTHON SOURCE LINES 308-312

.. code-block:: Python


    glm_est.scatter()





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_11_hrf_measured_005.png
   :alt: plot 11 hrf measured
   :srcset: /auto_examples/general/images/sphx_glr_plot_11_hrf_measured_005.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Axes: xlabel='Condition', ylabel='Theta'>



.. GENERATED FROM PYTHON SOURCE LINES 313-322

Fit GLM to all data and view topographic distribution
-----------------------------------------------------

Lastly we can run the GLM analysis on all sensors and plot the result on a
topomap.
We see the same result as in the MNE tutorial,
that activation is largest
contralateral to the tapping side. Also note that HbR tends to be the
negative of HbO as expected.

.. GENERATED FROM PYTHON SOURCE LINES 322-327

.. code-block:: Python


    glm_est = run_glm(raw_haemo, design_matrix)
    glm_est.plot_topo(conditions=["Tapping_Left", "Tapping_Right"])





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_11_hrf_measured_006.png
   :alt: Tapping_Left, Tapping_Right, Tapping_Left, Tapping_Right
   :srcset: /auto_examples/general/images/sphx_glr_plot_11_hrf_measured_006.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Figure size 1200x700 with 6 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 328-347

Note that the topographic visualisation is a high level representation
of the underlying data. This visual representation fits a smoothed surface
to the data and makes many assumptions including that the data is
spatially smooth and that the sensors sufficiently cover the scalp surface.
These assumptions can be violated with fNIRS due to the improved spatial
sensitivity (relative to EEG) and typically low number of sensors that are
unevenly distributed over the scalp.
As such, researchers should understand the underlying data and ensure that
the figure accurately reflects the effect of interest.

As an example of how the topoplot can be deceiving, we replot
the `Tapping/Right` condition from above for each hemisphere
separately. When both hemisphere are plotted together (left),
the function smooths
the large space between sensors, making the activity on the left hemisphere
smear towards the center and appear larger than the underlying data shows.
When each hemisphere is plotted independently (right) it becomes immediately
apparent that the data does not indicate that activity spreads across
the center of the head.

.. GENERATED FROM PYTHON SOURCE LINES 348-369

.. code-block:: Python


    fig, axes = plt.subplots(
        nrows=1, ncols=2, figsize=(10, 6), gridspec_kw=dict(width_ratios=[0.92, 1])
    )

    glm_hbo = glm_est.copy().pick(picks="hbo")
    conditions = ["Tapping_Right"]

    glm_hbo.plot_topo(axes=axes[0], colorbar=False, conditions=conditions)

    glm_hbo.copy().pick(picks=range(10)).plot_topo(
        conditions=conditions, axes=axes[1], colorbar=False, vlim=(-16, 16)
    )
    glm_hbo.copy().pick(picks=range(10, 20)).plot_topo(
        conditions=conditions, axes=axes[1], colorbar=False, vlim=(-16, 16)
    )

    axes[0].set_title("Smoothed across hemispheres")
    axes[1].set_title("Hemispheres plotted independently")





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_11_hrf_measured_007.png
   :alt: Smoothed across hemispheres, Hemispheres plotted independently
   :srcset: /auto_examples/general/images/sphx_glr_plot_11_hrf_measured_007.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    Text(0.5, 1.0, 'Hemispheres plotted independently')



.. GENERATED FROM PYTHON SOURCE LINES 370-372

Another way to view the data is to project the GLM estimates to the nearest
cortical surface

.. GENERATED FROM PYTHON SOURCE LINES 373-379

.. code-block:: Python


    glm_est.copy().surface_projection(
        condition="Tapping_Right", view="dorsal", chroma="hbo"
    )





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_11_hrf_measured_008.png
   :alt: plot 11 hrf measured
   :srcset: /auto_examples/general/images/sphx_glr_plot_11_hrf_measured_008.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <mne.viz._brain._brain.Brain object at 0x7ff37e148c40>



.. GENERATED FROM PYTHON SOURCE LINES 380-399

Analyse regions of interest
---------------------------

.. sidebar:: Relevant literature

   Zimeo Morais, G.A., Balardin, J.B. & Sato, J.R.
   fNIRS Optodesâ€™ Location Decider (fOLD): a toolbox for probe arrangement
   guided by brain regions-of-interest. Sci Rep 8, 3341 (2018).

   Shader and Luke et al. "The use of broad vs restricted regions of
   interest in functional near-infrared spectroscopy for measuring cortical
   activation to auditory-only and visual-only speech."
   Hearing Research (2021): `108256 <https://www.sciencedirect.com/science/article/pii/S0378595521000903>`_.

Or alternatively we can summarise the responses across regions of interest
for each condition. And you can plot it with your favorite software.
Region of interest analysis can be more robust than single channel analysis.
The fOLD toolbox can be used to assist in the design of ROIs.
And consideration should be paid to ensure optimal size ROIs are selected.

.. GENERATED FROM PYTHON SOURCE LINES 399-413

.. code-block:: Python


    left = [[1, 1], [1, 2], [1, 3], [2, 1], [2, 3], [2, 4], [3, 2], [3, 3], [4, 3], [4, 4]]
    right = [[5, 5], [5, 6], [5, 7], [6, 5], [6, 7], [6, 8], [7, 6], [7, 7], [8, 7], [8, 8]]

    groups = dict(
        Left_ROI=picks_pair_to_idx(raw_haemo, left),
        Right_ROI=picks_pair_to_idx(raw_haemo, right),
    )

    conditions = ["Control", "Tapping_Left", "Tapping_Right"]

    df = glm_est.to_dataframe_region_of_interest(groups, conditions)









.. GENERATED FROM PYTHON SOURCE LINES 414-417

As with the single channel results above, this is placed in a tidy dataframe
which contains conveniently extracted information, but now for the region
of interest.

.. GENERATED FROM PYTHON SOURCE LINES 417-421

.. code-block:: Python


    df







.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>ROI</th>
          <th>Condition</th>
          <th>Chroma</th>
          <th>theta</th>
          <th>se</th>
          <th>t</th>
          <th>dfe</th>
          <th>p</th>
          <th>Weighted</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>Left_ROI</td>
          <td>Control</td>
          <td>hbo</td>
          <td>-1.690850e-07</td>
          <td>0.906548</td>
          <td>-0.186515</td>
          <td>35</td>
          <td>8.531176e-01</td>
          <td>Inverse standard error</td>
        </tr>
        <tr>
          <th>1</th>
          <td>Left_ROI</td>
          <td>Control</td>
          <td>hbr</td>
          <td>1.621215e-07</td>
          <td>0.510929</td>
          <td>0.317307</td>
          <td>35</td>
          <td>7.528959e-01</td>
          <td>Inverse standard error</td>
        </tr>
        <tr>
          <th>2</th>
          <td>Right_ROI</td>
          <td>Control</td>
          <td>hbo</td>
          <td>3.814778e-08</td>
          <td>0.941335</td>
          <td>0.040525</td>
          <td>35</td>
          <td>9.679047e-01</td>
          <td>Inverse standard error</td>
        </tr>
        <tr>
          <th>3</th>
          <td>Right_ROI</td>
          <td>Control</td>
          <td>hbr</td>
          <td>-1.034544e-07</td>
          <td>0.532735</td>
          <td>-0.194195</td>
          <td>35</td>
          <td>8.471461e-01</td>
          <td>Inverse standard error</td>
        </tr>
        <tr>
          <th>0</th>
          <td>Left_ROI</td>
          <td>Tapping_Left</td>
          <td>hbo</td>
          <td>4.808888e-06</td>
          <td>0.919870</td>
          <td>5.227791</td>
          <td>35</td>
          <td>8.051619e-06</td>
          <td>Inverse standard error</td>
        </tr>
        <tr>
          <th>1</th>
          <td>Left_ROI</td>
          <td>Tapping_Left</td>
          <td>hbr</td>
          <td>-1.837941e-06</td>
          <td>0.518407</td>
          <td>-3.545361</td>
          <td>35</td>
          <td>1.136272e-03</td>
          <td>Inverse standard error</td>
        </tr>
        <tr>
          <th>2</th>
          <td>Right_ROI</td>
          <td>Tapping_Left</td>
          <td>hbo</td>
          <td>9.219006e-06</td>
          <td>0.955125</td>
          <td>9.652143</td>
          <td>35</td>
          <td>2.123476e-11</td>
          <td>Inverse standard error</td>
        </tr>
        <tr>
          <th>3</th>
          <td>Right_ROI</td>
          <td>Tapping_Left</td>
          <td>hbr</td>
          <td>-3.877839e-06</td>
          <td>0.540531</td>
          <td>-7.174123</td>
          <td>35</td>
          <td>2.280434e-08</td>
          <td>Inverse standard error</td>
        </tr>
        <tr>
          <th>0</th>
          <td>Left_ROI</td>
          <td>Tapping_Right</td>
          <td>hbo</td>
          <td>9.738244e-06</td>
          <td>0.922471</td>
          <td>10.556691</td>
          <td>35</td>
          <td>2.015806e-12</td>
          <td>Inverse standard error</td>
        </tr>
        <tr>
          <th>1</th>
          <td>Left_ROI</td>
          <td>Tapping_Right</td>
          <td>hbr</td>
          <td>-3.240867e-06</td>
          <td>0.519857</td>
          <td>-6.234145</td>
          <td>35</td>
          <td>3.799977e-07</td>
          <td>Inverse standard error</td>
        </tr>
        <tr>
          <th>2</th>
          <td>Right_ROI</td>
          <td>Tapping_Right</td>
          <td>hbo</td>
          <td>5.997574e-06</td>
          <td>0.957747</td>
          <td>6.262169</td>
          <td>35</td>
          <td>3.491383e-07</td>
          <td>Inverse standard error</td>
        </tr>
        <tr>
          <th>3</th>
          <td>Right_ROI</td>
          <td>Tapping_Right</td>
          <td>hbr</td>
          <td>-2.408893e-06</td>
          <td>0.542023</td>
          <td>-4.444261</td>
          <td>35</td>
          <td>8.484410e-05</td>
          <td>Inverse standard error</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 422-430

Compute contrasts
-----------------

We can also define a contrast as described in
`Nilearn docs <http://nilearn.github.io/auto_examples/04_glm_first_level/plot_localizer_surface_analysis.html>`__
and plot it.
Here we contrast the response to tapping on the left hand with the response
from tapping on the right hand.

.. GENERATED FROM PYTHON SOURCE LINES 431-442

.. code-block:: Python


    contrast_matrix = np.eye(design_matrix.shape[1])
    basic_conts = dict(
        [(column, contrast_matrix[i]) for i, column in enumerate(design_matrix.columns)]
    )
    contrast_LvR = basic_conts["Tapping_Left"] - basic_conts["Tapping_Right"]

    contrast = glm_est.compute_contrast(contrast_LvR)
    contrast.plot_topo()





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_11_hrf_measured_009.png
   :alt: Oxyhaemoglobin, Deoxyhaemoglobin
   :srcset: /auto_examples/general/images/sphx_glr_plot_11_hrf_measured_009.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Figure size 1200x700 with 3 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 443-457

Export Results
---------------

.. sidebar:: Relevant literature

   Wickham, Hadley. "Tidy data." Journal of Statistical Software 59.10 (2014): 1-23.

Here we export the data in a tidy pandas data frame.
We export the GLM results for every channel and condition.
Data is exported in long format by default.
However, a helper function is also provided to convert the long data to wide format.
The long to wide conversion also adds some additional derived data, such as
if a significant response (p<0.05) was observed, which sensor and detector is
in the channel, which chroma, etc.

.. GENERATED FROM PYTHON SOURCE LINES 457-461

.. code-block:: Python


    df = glm_est.to_dataframe()









.. GENERATED FROM PYTHON SOURCE LINES 462-469

Determine true and false positive rates
---------------------------------------

We can query the exported data frames to determine the true and false
positive rates. Note: optodes cover a greater region than just the
motor cortex, so we dont expect 100% of channels to detect responses to
the tapping, but we do expect 5% or less for the false positive rate.

.. GENERATED FROM PYTHON SOURCE LINES 469-476

.. code-block:: Python


    (
        df.query('Condition in ["Control", "Tapping_Left", "Tapping_Right"]')
        .drop(["df", "mse", "p_value", "t"], axis=1)
        .groupby(["Condition", "Chroma", "ch_name"])
        .agg(["mean"])
    )





.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead tr th {
            text-align: left;
        }

        .dataframe thead tr:last-of-type th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr>
          <th></th>
          <th></th>
          <th>variable</th>
          <th>se</th>
          <th>theta</th>
          <th>Source</th>
          <th>Detector</th>
          <th>Significant</th>
        </tr>
        <tr>
          <th></th>
          <th></th>
          <th></th>
          <th>mean</th>
          <th>mean</th>
          <th>mean</th>
          <th>mean</th>
          <th>mean</th>
        </tr>
        <tr>
          <th>Condition</th>
          <th>Chroma</th>
          <th>ch_name</th>
          <th></th>
          <th></th>
          <th></th>
          <th></th>
          <th></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th rowspan="5" valign="top">Control</th>
          <th rowspan="5" valign="top">hbo</th>
          <th>S1_D1 hbo</th>
          <td>1.066677e-06</td>
          <td>7.767152e-07</td>
          <td>1.0</td>
          <td>1.0</td>
          <td>0.0</td>
        </tr>
        <tr>
          <th>S1_D2 hbo</th>
          <td>7.491500e-07</td>
          <td>-4.497856e-08</td>
          <td>1.0</td>
          <td>2.0</td>
          <td>0.0</td>
        </tr>
        <tr>
          <th>S1_D3 hbo</th>
          <td>7.672949e-07</td>
          <td>4.646158e-07</td>
          <td>1.0</td>
          <td>3.0</td>
          <td>0.0</td>
        </tr>
        <tr>
          <th>S2_D1 hbo</th>
          <td>6.342857e-07</td>
          <td>-5.627240e-07</td>
          <td>2.0</td>
          <td>1.0</td>
          <td>0.0</td>
        </tr>
        <tr>
          <th>S2_D3 hbo</th>
          <td>8.390797e-07</td>
          <td>8.605292e-07</td>
          <td>2.0</td>
          <td>3.0</td>
          <td>0.0</td>
        </tr>
        <tr>
          <th>...</th>
          <th>...</th>
          <th>...</th>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
        </tr>
        <tr>
          <th rowspan="5" valign="top">Tapping_Right</th>
          <th rowspan="5" valign="top">hbr</th>
          <th>S6_D8 hbr</th>
          <td>7.334896e-07</td>
          <td>-4.239772e-06</td>
          <td>6.0</td>
          <td>8.0</td>
          <td>1.0</td>
        </tr>
        <tr>
          <th>S7_D6 hbr</th>
          <td>6.292325e-07</td>
          <td>-1.893321e-06</td>
          <td>7.0</td>
          <td>6.0</td>
          <td>1.0</td>
        </tr>
        <tr>
          <th>S7_D7 hbr</th>
          <td>4.903269e-07</td>
          <td>-2.039497e-06</td>
          <td>7.0</td>
          <td>7.0</td>
          <td>1.0</td>
        </tr>
        <tr>
          <th>S8_D7 hbr</th>
          <td>6.149382e-07</td>
          <td>-2.704977e-06</td>
          <td>8.0</td>
          <td>7.0</td>
          <td>1.0</td>
        </tr>
        <tr>
          <th>S8_D8 hbr</th>
          <td>1.203101e-06</td>
          <td>-2.265968e-06</td>
          <td>8.0</td>
          <td>8.0</td>
          <td>0.0</td>
        </tr>
      </tbody>
    </table>
    <p>120 rows Ã— 5 columns</p>
    </div>
    </div>
    <br />
    <br />


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 20.045 seconds)

**Estimated memory usage:**  714 MB


.. _sphx_glr_download_auto_examples_general_plot_11_hrf_measured.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/mne-tools/mne-nirs/gh-pages?filepath=stable/notebooks/auto_examples/general/plot_11_hrf_measured.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_11_hrf_measured.ipynb <plot_11_hrf_measured.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_11_hrf_measured.py <plot_11_hrf_measured.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_11_hrf_measured.zip <plot_11_hrf_measured.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
