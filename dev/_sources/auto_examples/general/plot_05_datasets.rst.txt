
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/general/plot_05_datasets.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_general_plot_05_datasets.py>`
        to download the full example code. or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_general_plot_05_datasets.py:


.. _ex-fnirs-datasets:

================
Example Datasets
================

To get you up and running with MNE-NIRS and fNIRS data analysis we provide
some example datasets.
Each dataset is published and if you use the data at any stage of
your experiment (including piloting and exploration) then please cite the
authors of the data.

A brief explanation of each dataset is provided below, and a demonstration
of how to download the data and address it with MNE.
Each dataset is provided in BIDs format, as such we can use the MNE-BIDS
package to quickly report the number of trials for each condition in the
dataset.

.. GENERATED FROM PYTHON SOURCE LINES 21-31

.. code-block:: Python

    # sphinx_gallery_thumbnail_number = 1

    # Authors: Robert Luke <mail@robertluke.net>
    #
    # License: BSD (3-clause)

    import mne_bids.stats

    import mne_nirs








.. GENERATED FROM PYTHON SOURCE LINES 32-44

*******************
Finger Tapping Data
*******************

This data is from the publication
:footcite:p:`Luke_fNIRS_Finger_Tapping_2021`.
This data provides an example of the canonical finger tapping experiment.
Data is provided from five participants. The experiment was a block design
with three conditions. The first condition consisted of the participants
tapping their thumb to fingers on the left hand, the second condition was the
same but with the right hand. The final condition was a control, with no
motor task.

.. GENERATED FROM PYTHON SOURCE LINES 44-49

.. code-block:: Python


    datapath = mne_nirs.datasets.fnirs_motor_group.data_path()
    mne_bids.stats.count_events(datapath)







.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead tr th {
            text-align: left;
        }

        .dataframe thead tr:last-of-type th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr>
          <th></th>
          <th colspan="4" halign="left">tapping</th>
        </tr>
        <tr>
          <th>trial_type</th>
          <th>15.0</th>
          <th>Control</th>
          <th>Tapping/Left</th>
          <th>Tapping/Right</th>
        </tr>
        <tr>
          <th>subject</th>
          <th></th>
          <th></th>
          <th></th>
          <th></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>01</th>
          <td>2</td>
          <td>30</td>
          <td>30</td>
          <td>30</td>
        </tr>
        <tr>
          <th>02</th>
          <td>2</td>
          <td>30</td>
          <td>30</td>
          <td>30</td>
        </tr>
        <tr>
          <th>03</th>
          <td>2</td>
          <td>30</td>
          <td>30</td>
          <td>30</td>
        </tr>
        <tr>
          <th>04</th>
          <td>2</td>
          <td>30</td>
          <td>30</td>
          <td>30</td>
        </tr>
        <tr>
          <th>05</th>
          <td>2</td>
          <td>30</td>
          <td>30</td>
          <td>30</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 50-61

*************************
Auditory Speech and Noise
*************************

This data is from the publication
:footcite:p:`luke2021analysis`.
In this experiment listeners were presented with auditory stimuli via insertphones.
Data is provided from seventeen participants. The experiment was a block
design with three conditions. The first condition consisted of speech,
the second condition consisted of low frequency noise.
The final condition was a control, no audio was presented to the listeners.

.. GENERATED FROM PYTHON SOURCE LINES 61-66

.. code-block:: Python


    datapath = mne_nirs.datasets.block_speech_noise.data_path()
    mne_bids.stats.count_events(datapath)







.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead tr th {
            text-align: left;
        }

        .dataframe thead tr:last-of-type th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr>
          <th></th>
          <th></th>
          <th colspan="3" halign="left">AudioSpeechNoise</th>
        </tr>
        <tr>
          <th></th>
          <th>trial_type</th>
          <th>Control</th>
          <th>Noise</th>
          <th>Speech</th>
        </tr>
        <tr>
          <th>subject</th>
          <th>session</th>
          <th></th>
          <th></th>
          <th></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>01</th>
          <th>01</th>
          <td>20</td>
          <td>20</td>
          <td>20</td>
        </tr>
        <tr>
          <th>02</th>
          <th>01</th>
          <td>20</td>
          <td>20</td>
          <td>20</td>
        </tr>
        <tr>
          <th>03</th>
          <th>01</th>
          <td>20</td>
          <td>20</td>
          <td>20</td>
        </tr>
        <tr>
          <th>04</th>
          <th>01</th>
          <td>20</td>
          <td>20</td>
          <td>20</td>
        </tr>
        <tr>
          <th>05</th>
          <th>01</th>
          <td>20</td>
          <td>20</td>
          <td>20</td>
        </tr>
        <tr>
          <th>06</th>
          <th>01</th>
          <td>20</td>
          <td>20</td>
          <td>20</td>
        </tr>
        <tr>
          <th>07</th>
          <th>01</th>
          <td>20</td>
          <td>20</td>
          <td>20</td>
        </tr>
        <tr>
          <th>08</th>
          <th>01</th>
          <td>20</td>
          <td>20</td>
          <td>20</td>
        </tr>
        <tr>
          <th>09</th>
          <th>01</th>
          <td>20</td>
          <td>20</td>
          <td>20</td>
        </tr>
        <tr>
          <th>10</th>
          <th>01</th>
          <td>20</td>
          <td>20</td>
          <td>20</td>
        </tr>
        <tr>
          <th>11</th>
          <th>01</th>
          <td>20</td>
          <td>20</td>
          <td>20</td>
        </tr>
        <tr>
          <th>12</th>
          <th>01</th>
          <td>20</td>
          <td>20</td>
          <td>20</td>
        </tr>
        <tr>
          <th>13</th>
          <th>01</th>
          <td>20</td>
          <td>20</td>
          <td>20</td>
        </tr>
        <tr>
          <th>14</th>
          <th>01</th>
          <td>20</td>
          <td>20</td>
          <td>20</td>
        </tr>
        <tr>
          <th>15</th>
          <th>01</th>
          <td>20</td>
          <td>20</td>
          <td>20</td>
        </tr>
        <tr>
          <th>16</th>
          <th>01</th>
          <td>20</td>
          <td>20</td>
          <td>20</td>
        </tr>
        <tr>
          <th>17</th>
          <th>01</th>
          <td>20</td>
          <td>20</td>
          <td>20</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 67-78

**********************
Audio or Visual Speech
**********************

This data is from the publication
:footcite:p:`shader2021use`.
In this experiment participants were presented a continuously running story
in blocked segments. Each segment was presented as either audio only
or visual only.
In addition to the audio visual stimuli, a control condition was also
presented randomly throughout the experiment.

.. GENERATED FROM PYTHON SOURCE LINES 78-83

.. code-block:: Python


    datapath = mne_nirs.datasets.audio_or_visual_speech.data_path()
    mne_bids.stats.count_events(datapath)







.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead tr th {
            text-align: left;
        }

        .dataframe thead tr:last-of-type th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr>
          <th></th>
          <th></th>
          <th colspan="3" halign="left">AudioVisualBroadVsRestricted</th>
        </tr>
        <tr>
          <th></th>
          <th>trial_type</th>
          <th>Audio</th>
          <th>Control</th>
          <th>Video</th>
        </tr>
        <tr>
          <th>subject</th>
          <th>session</th>
          <th></th>
          <th></th>
          <th></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>01</th>
          <th>01</th>
          <td>18</td>
          <td>10</td>
          <td>18</td>
        </tr>
        <tr>
          <th>02</th>
          <th>01</th>
          <td>18</td>
          <td>10</td>
          <td>18</td>
        </tr>
        <tr>
          <th>03</th>
          <th>01</th>
          <td>18</td>
          <td>10</td>
          <td>18</td>
        </tr>
        <tr>
          <th>04</th>
          <th>01</th>
          <td>18</td>
          <td>10</td>
          <td>18</td>
        </tr>
        <tr>
          <th>05</th>
          <th>01</th>
          <td>18</td>
          <td>10</td>
          <td>18</td>
        </tr>
        <tr>
          <th>06</th>
          <th>01</th>
          <td>18</td>
          <td>10</td>
          <td>18</td>
        </tr>
        <tr>
          <th>07</th>
          <th>01</th>
          <td>18</td>
          <td>10</td>
          <td>18</td>
        </tr>
        <tr>
          <th>08</th>
          <th>01</th>
          <td>18</td>
          <td>10</td>
          <td>18</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 84-88

Bibliography
-----------------------------------------------

.. footbibliography::


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 1.306 seconds)

**Estimated memory usage:**  446 MB


.. _sphx_glr_download_auto_examples_general_plot_05_datasets.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/mne-tools/mne-nirs/gh-pages?filepath=stable/notebooks/auto_examples/general/plot_05_datasets.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_05_datasets.ipynb <plot_05_datasets.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_05_datasets.py <plot_05_datasets.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_05_datasets.zip <plot_05_datasets.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
