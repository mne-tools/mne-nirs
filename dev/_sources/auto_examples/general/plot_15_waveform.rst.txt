
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/general/plot_15_waveform.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_general_plot_15_waveform.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_general_plot_15_waveform.py:


.. _tut-fnirs-processing:

Waveform Averaging Analysis
===========================

.. note:: This tutorial is a mirror of the
          (`MNE tutorial <https://mne.tools/stable/auto_tutorials/preprocessing/plot_70_fnirs_processing.html>`__),
          and is reproduced in MNE-NIRS for convenience and so that all
          relevant material is easily accessible to users.

This tutorial covers how to convert functional near-infrared spectroscopy
(fNIRS) data from raw measurements to relative oxyhaemoglobin (HbO) and
deoxyhaemoglobin (HbR) concentration, view the average waveform, and
topographic representation of the response.

Here we will work with the :ref:`fNIRS motor data <mne:fnirs-motor-dataset>`.

.. GENERATED FROM PYTHON SOURCE LINES 19-25

.. code-block:: Python

    # sphinx_gallery_thumbnail_number = 14

    # Authors: Robert Luke <mail@robertluke.net>
    #
    # License: BSD (3-clause)








.. GENERATED FROM PYTHON SOURCE LINES 26-41

.. code-block:: Python


    import os.path as op
    import numpy as np
    import matplotlib.pyplot as plt
    from itertools import compress

    import mne


    fnirs_data_folder = mne.datasets.fnirs_motor.data_path()
    fnirs_cw_amplitude_dir = op.join(fnirs_data_folder, 'Participant-1')
    raw_intensity = mne.io.read_raw_nirx(fnirs_cw_amplitude_dir, verbose=True)
    raw_intensity.load_data()






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Loading /home/circleci/mne_data/MNE-fNIRS-motor-data/Participant-1
    Reading 0 ... 23238  =      0.000 ...  2974.464 secs...


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <details open>
        <summary><strong>General</strong></summary>
        <table class="table table-hover table-striped table-sm table-responsive small">
            <tr>
                <th>Measurement date</th>
            
                <td>November 02, 2019  13:16:16 GMT</td>
            
            </tr>
            <tr>
                <th>Experimenter</th>
            
                <td>Unknown</td>
            
            </tr>
            <tr>
                <th>Participant</th>
            
            
                <td>P1</td>
            
            
            </tr>
        </table>
        </details>
        <details open>
            <summary><strong>Channels</strong></summary>
            <table class="table table-hover table-striped table-sm table-responsive small">
                <tr>
                    <th>Digitized points</th>
                
                    <td>31 points</td>
                
                </tr>
                <tr>
                    <th>Good channels</th>
                    <td>56 fNIRS (CW amplitude)</td>
                </tr>
                <tr>
                    <th>Bad channels</th>
                    <td>None</td>
                </tr>
                <tr>
                    <th>EOG channels</th>
                    <td>Not available</td>
                </tr>
                <tr>
                    <th>ECG channels</th>
                    <td>Not available</td>
                </tr>
            </table>
            </details>
            <details open>
                <summary><strong>Data</strong></summary>
                <table class="table table-hover table-striped table-sm table-responsive small">
                
                    <tr>
                        <th>Sampling frequency</th>
                        <td>7.81 Hz</td>
                    </tr>
                
                
                    <tr>
                        <th>Highpass</th>
                        <td>0.00 Hz</td>
                    </tr>
                
                
                    <tr>
                        <th>Lowpass</th>
                        <td>3.91 Hz</td>
                    </tr>
                
                
                
                    <tr>
                        <th>Filenames</th>
                        <td>Participant-1</td>
                    </tr>
                
                
                    <tr>
                        <th>Duration</th>
                        <td>00:49:35 (HH:MM:SS)</td>
                    </tr>
                
                </table>
                </details>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 42-50

Providing more meaningful annotation information
------------------------------------------------

First, we attribute more meaningful names to the trigger codes which are
stored as annotations. Second, we include information about the duration of
each stimulus, which was 5 seconds for all conditions in this experiment.
Third, we remove the trigger code 15, which signaled the start and end
of the experiment and is not relevant to our analysis.

.. GENERATED FROM PYTHON SOURCE LINES 50-59

.. code-block:: Python


    raw_intensity.annotations.set_durations(5)
    raw_intensity.annotations.rename({'1.0': 'Control',
                                      '2.0': 'Tapping/Left',
                                      '3.0': 'Tapping/Right'})
    unwanted = np.nonzero(raw_intensity.annotations.description == '15.0')
    raw_intensity.annotations.delete(unwanted)









.. GENERATED FROM PYTHON SOURCE LINES 60-68

Viewing location of sensors over brain surface
----------------------------------------------

Here we validate that the location of sources-detector pairs and channels
are in the expected locations. Source-detector pairs are shown as lines
between the optodes, channels (the mid point of source-detector pairs) are
optionally shown as orange dots. Source are optionally shown as red dots and
detectors as black.

.. GENERATED FROM PYTHON SOURCE LINES 68-78

.. code-block:: Python


    subjects_dir = op.join(mne.datasets.sample.data_path(), 'subjects')

    brain = mne.viz.Brain(
        'fsaverage', subjects_dir=subjects_dir, background='w', cortex='0.5')
    brain.add_sensors(
        raw_intensity.info, trans='fsaverage',
        fnirs=['channels', 'pairs', 'sources', 'detectors'])
    brain.show_view(azimuth=20, elevation=60, distance=400)




.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_001.png
   :alt: plot 15 waveform
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Channel types:: fnirs_cw_amplitude: 56




.. GENERATED FROM PYTHON SOURCE LINES 79-86

Selecting channels appropriate for detecting neural responses
-------------------------------------------------------------

First we remove channels that are too close together (short channels) to
detect a neural response (less than 1 cm distance between optodes).
These short channels can be seen in the figure above.
To achieve this we pick all the channels that are not considered to be short.

.. GENERATED FROM PYTHON SOURCE LINES 86-95

.. code-block:: Python


    picks = mne.pick_types(raw_intensity.info, meg=False, fnirs=True)
    dists = mne.preprocessing.nirs.source_detector_distances(
        raw_intensity.info, picks=picks)
    raw_intensity.pick(picks[dists > 0.01])
    raw_intensity.plot(n_channels=len(raw_intensity.ch_names),
                       duration=500, show_scrollbars=False)





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_002.png
   :alt: Raw plot
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <mne_qt_browser._pg_figure.MNEQtBrowser(0x0) at 0x7ff2a8870080>



.. GENERATED FROM PYTHON SOURCE LINES 96-100

Converting from raw intensity to optical density
------------------------------------------------

The raw intensity values are then converted to optical density.

.. GENERATED FROM PYTHON SOURCE LINES 100-106

.. code-block:: Python


    raw_od = mne.preprocessing.nirs.optical_density(raw_intensity)
    raw_od.plot(n_channels=len(raw_od.ch_names),
                duration=500, show_scrollbars=False)





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_003.png
   :alt: Raw plot
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <mne_qt_browser._pg_figure.MNEQtBrowser(0x0) at 0x7ff2a87d2a80>



.. GENERATED FROM PYTHON SOURCE LINES 107-118

Evaluating the quality of the data
----------------------------------

At this stage we can quantify the quality of the coupling
between the scalp and the optodes using the scalp coupling index. This
method looks for the presence of a prominent synchronous signal in the
frequency range of cardiac signals across both photodetected signals.

In this example the data is clean and the coupling is good for all
channels, so we will not mark any channels as bad based on the scalp
coupling index.

.. GENERATED FROM PYTHON SOURCE LINES 118-125

.. code-block:: Python


    sci = mne.preprocessing.nirs.scalp_coupling_index(raw_od)
    fig, ax = plt.subplots()
    ax.hist(sci)
    ax.set(xlabel='Scalp Coupling Index', ylabel='Count', xlim=[0, 1])





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_004.png
   :alt: plot 15 waveform
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_004.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    [Text(0.5, 23.52222222222222, 'Scalp Coupling Index'), Text(47.097222222222214, 0.5, 'Count'), (0.0, 1.0)]



.. GENERATED FROM PYTHON SOURCE LINES 126-128

In this example we will mark all channels with a SCI less than 0.5 as bad
(this dataset is quite clean, so no channels are marked as bad).

.. GENERATED FROM PYTHON SOURCE LINES 128-132

.. code-block:: Python


    raw_od.info['bads'] = list(compress(raw_od.ch_names, sci < 0.5))









.. GENERATED FROM PYTHON SOURCE LINES 133-139

At this stage it is appropriate to inspect your data
(for instructions on how to use the interactive data visualisation tool
see :ref:`tut-visualize-raw`)
to ensure that channels with poor scalp coupling have been removed.
If your data contains lots of artifacts you may decide to apply
artifact reduction techniques as described in :ref:`ex-fnirs-artifacts`.

.. GENERATED FROM PYTHON SOURCE LINES 142-147

Converting from optical density to haemoglobin
----------------------------------------------

Next we convert the optical density data to haemoglobin concentration using
the modified Beer-Lambert law.

.. GENERATED FROM PYTHON SOURCE LINES 147-153

.. code-block:: Python


    raw_haemo = mne.preprocessing.nirs.beer_lambert_law(raw_od, ppf=0.1)
    raw_haemo.plot(n_channels=len(raw_haemo.ch_names),
                   duration=500, show_scrollbars=False)





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_005.png
   :alt: Raw plot
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_005.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <mne_qt_browser._pg_figure.MNEQtBrowser(0x0) at 0x7ff274f2cf00>



.. GENERATED FROM PYTHON SOURCE LINES 154-162

Removing heart rate from signal
-------------------------------

The haemodynamic response has frequency content predominantly below 0.5 Hz.
An increase in activity around 1 Hz can be seen in the data that is due to
the person's heart beat and is unwanted. So we use a low pass filter to
remove this. A high pass filter is also included to remove slow drifts
in the data.

.. GENERATED FROM PYTHON SOURCE LINES 162-170

.. code-block:: Python


    fig = raw_haemo.plot_psd(average=True)
    fig.suptitle('Before filtering', weight='bold', size='x-large')
    raw_haemo = raw_haemo.filter(0.05, 0.7, h_trans_bandwidth=0.2,
                                 l_trans_bandwidth=0.02)
    fig = raw_haemo.plot_psd(average=True)
    fig.suptitle('After filtering', weight='bold', size='x-large')




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_006.png
         :alt: Before filtering, Oxyhemoglobin, Deoxyhemoglobin
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_006.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_007.png
         :alt: After filtering, Oxyhemoglobin, Deoxyhemoglobin
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_007.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    NOTE: plot_psd() is a legacy function. New code should use .compute_psd().plot().
    Effective window size : 262.144 (s)
    Filtering raw data in 1 contiguous segment
    Setting up band-pass filter from 0.05 - 0.7 Hz

    FIR filter parameters
    ---------------------
    Designing a one-pass, zero-phase, non-causal bandpass filter:
    - Windowed time-domain design (firwin) method
    - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation
    - Lower passband edge: 0.05
    - Lower transition bandwidth: 0.02 Hz (-6 dB cutoff frequency: 0.04 Hz)
    - Upper passband edge: 0.70 Hz
    - Upper transition bandwidth: 0.20 Hz (-6 dB cutoff frequency: 0.80 Hz)
    - Filter length: 1291 samples (165.248 s)

    [Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s
    NOTE: plot_psd() is a legacy function. New code should use .compute_psd().plot().
    Effective window size : 262.144 (s)

    Text(0.5, 0.993055, 'After filtering')



.. GENERATED FROM PYTHON SOURCE LINES 171-180

Extract epochs
--------------

Now that the signal has been converted to relative haemoglobin concentration,
and the unwanted heart rate component has been removed, we can extract epochs
related to each of the experimental conditions.

First we extract the events of interest and visualise them to ensure they are
correct.

.. GENERATED FROM PYTHON SOURCE LINES 180-186

.. code-block:: Python


    events, event_dict = mne.events_from_annotations(raw_haemo)
    fig = mne.viz.plot_events(events, event_id=event_dict,
                              sfreq=raw_haemo.info['sfreq'])





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_008.png
   :alt: plot 15 waveform
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_008.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Used Annotations descriptions: ['Control', 'Tapping/Left', 'Tapping/Right']




.. GENERATED FROM PYTHON SOURCE LINES 187-190

Next we define the range of our epochs, the rejection criteria,
baseline correction, and extract the epochs. We visualise the log of which
epochs were dropped.

.. GENERATED FROM PYTHON SOURCE LINES 190-202

.. code-block:: Python


    reject_criteria = dict(hbo=80e-6)
    tmin, tmax = -5, 15

    epochs = mne.Epochs(raw_haemo, events, event_id=event_dict,
                        tmin=tmin, tmax=tmax,
                        reject=reject_criteria, reject_by_annotation=True,
                        proj=True, baseline=(None, 0), preload=True,
                        detrend=None, verbose=True)
    epochs.plot_drop_log()





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_009.png
   :alt: 6 of 90 epochs removed (6.7%)
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_009.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Not setting metadata
    90 matching events found
    Setting baseline interval to [-4.992, 0.0] s
    Applying baseline correction (mode: mean)
    0 projection items activated
    Using data from preloaded Raw for 90 events and 157 original time points ...
        Rejecting  epoch based on HBO : ['S4_D4 hbo']
        Rejecting  epoch based on HBO : ['S4_D4 hbo', 'S8_D8 hbo']
        Rejecting  epoch based on HBO : ['S4_D4 hbo']
        Rejecting  epoch based on HBO : ['S4_D4 hbo', 'S8_D8 hbo']
        Rejecting  epoch based on HBO : ['S1_D1 hbo', 'S3_D3 hbo', 'S4_D4 hbo', 'S7_D6 hbo', 'S7_D7 hbo', 'S8_D8 hbo']
        Rejecting  epoch based on HBO : ['S4_D4 hbo', 'S6_D8 hbo', 'S8_D8 hbo']
    6 bad epochs dropped

    <Figure size 640x480 with 1 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 203-211

View consistency of responses across trials
-------------------------------------------

Now we can view the haemodynamic response for our tapping condition.
We visualise the response for both the oxy- and deoxyhaemoglobin, and
observe the expected peak in HbO at around 6 seconds consistently across
trials, and the consistent dip in HbR that is slightly delayed relative to
the HbO peak.

.. GENERATED FROM PYTHON SOURCE LINES 211-217

.. code-block:: Python


    epochs['Tapping'].plot_image(combine='mean', vmin=-30, vmax=30,
                                 ts_args=dict(ylim=dict(hbo=[-15, 15],
                                                        hbr=[-15, 15])))





.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_010.png
         :alt: Oxyhemoglobin (mean), µM
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_010.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_011.png
         :alt: Deoxyhemoglobin (mean), µM
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_011.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Not setting metadata
    55 matching events found
    No baseline correction applied
    0 projection items activated
    Not setting metadata
    55 matching events found
    No baseline correction applied
    0 projection items activated
    combining channels using "mean"
    combining channels using "mean"

    [<Figure size 640x480 with 3 Axes>, <Figure size 640x480 with 3 Axes>]



.. GENERATED FROM PYTHON SOURCE LINES 218-220

We can also view the epoched data for the control condition and observe
that it does not show the expected morphology.

.. GENERATED FROM PYTHON SOURCE LINES 220-226

.. code-block:: Python


    epochs['Control'].plot_image(combine='mean', vmin=-30, vmax=30,
                                 ts_args=dict(ylim=dict(hbo=[-15, 15],
                                                        hbr=[-15, 15])))





.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_012.png
         :alt: Oxyhemoglobin (mean), µM
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_012.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_013.png
         :alt: Deoxyhemoglobin (mean), µM
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_013.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Not setting metadata
    29 matching events found
    No baseline correction applied
    0 projection items activated
    Not setting metadata
    29 matching events found
    No baseline correction applied
    0 projection items activated
    combining channels using "mean"
    combining channels using "mean"

    [<Figure size 640x480 with 3 Axes>, <Figure size 640x480 with 3 Axes>]



.. GENERATED FROM PYTHON SOURCE LINES 227-233

View consistency of responses across channels
---------------------------------------------

Similarly we can view how consistent the response is across the optode
pairs that we selected. All the channels in this data are located over the
motor cortex, and all channels show a similar pattern in the data.

.. GENERATED FROM PYTHON SOURCE LINES 233-243

.. code-block:: Python


    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 6))
    clims = dict(hbo=[-20, 20], hbr=[-20, 20])
    epochs['Control'].average().plot_image(axes=axes[:, 0], clim=clims)
    epochs['Tapping'].average().plot_image(axes=axes[:, 1], clim=clims)
    for column, condition in enumerate(['Control', 'Tapping']):
        for ax in axes[:, column]:
            ax.set_title('{}: {}'.format(condition, ax.get_title()))





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_014.png
   :alt: Control: Oxyhemoglobin (20 channels), Tapping: Oxyhemoglobin (20 channels), Control: Deoxyhemoglobin (20 channels), Tapping: Deoxyhemoglobin (20 channels), µM, µM, µM, µM
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_014.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 244-250

Plot standard fNIRS response image
----------------------------------

Next we generate the most common visualisation of fNIRS data: plotting
both the HbO and HbR on the same figure to illustrate the relation between
the two signals.

.. GENERATED FROM PYTHON SOURCE LINES 250-267

.. code-block:: Python


    evoked_dict = {'Tapping/HbO': epochs['Tapping'].average(picks='hbo'),
                   'Tapping/HbR': epochs['Tapping'].average(picks='hbr'),
                   'Control/HbO': epochs['Control'].average(picks='hbo'),
                   'Control/HbR': epochs['Control'].average(picks='hbr')}

    # Rename channels until the encoding of frequency in ch_name is fixed
    for condition in evoked_dict:
        evoked_dict[condition].rename_channels(lambda x: x[:-4])

    color_dict = dict(HbO='#AA3377', HbR='b')
    styles_dict = dict(Control=dict(linestyle='dashed'))

    mne.viz.plot_compare_evokeds(evoked_dict, combine="mean", ci=0.95,
                                 colors=color_dict, styles=styles_dict)





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_015.png
   :alt: plot 15 waveform
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_015.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    combining channels using "mean"
    combining channels using "mean"
    combining channels using "mean"
    combining channels using "mean"

    [<Figure size 800x600 with 1 Axes>]



.. GENERATED FROM PYTHON SOURCE LINES 268-272

View topographic representation of activity
-------------------------------------------

Next we view how the topographic activity changes throughout the response.

.. GENERATED FROM PYTHON SOURCE LINES 272-279

.. code-block:: Python


    times = np.arange(-3.5, 13.2, 3.0)
    topomap_args = dict(extrapolate='local')
    epochs['Tapping'].average(picks='hbo').plot_joint(
        times=times, topomap_args=topomap_args)





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_016.png
   :alt: Oxyhemoglobin (20 channels), -3.500 s, -0.500 s, 2.500 s, 5.500 s, 8.500 s, 11.500 s
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_016.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    No projector specified for this dataset. Please consider the method self.add_proj.

    <Figure size 800x420 with 9 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 280-285

Compare tapping of left and right hands
---------------------------------------

Finally we generate topo maps for the left and right conditions to view
the location of activity. First we visualise the HbO activity.

.. GENERATED FROM PYTHON SOURCE LINES 285-292

.. code-block:: Python


    times = np.arange(4.0, 11.0, 1.0)
    epochs['Tapping/Left'].average(picks='hbo').plot_topomap(
        times=times, **topomap_args)
    epochs['Tapping/Right'].average(picks='hbo').plot_topomap(
        times=times, **topomap_args)




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_017.png
         :alt: 4.000 s, 5.000 s, 6.000 s, 7.000 s, 8.000 s, 9.000 s, 10.000 s, µM
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_017.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_018.png
         :alt: 4.000 s, 5.000 s, 6.000 s, 7.000 s, 8.000 s, 9.000 s, 10.000 s, µM
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_018.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <MNEFigure size 1050x220 with 8 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 293-294

And we also view the HbR activity for the two conditions.

.. GENERATED FROM PYTHON SOURCE LINES 294-300

.. code-block:: Python


    epochs['Tapping/Left'].average(picks='hbr').plot_topomap(
        times=times, **topomap_args)
    epochs['Tapping/Right'].average(picks='hbr').plot_topomap(
        times=times, **topomap_args)




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_019.png
         :alt: 4.000 s, 5.000 s, 6.000 s, 7.000 s, 8.000 s, 9.000 s, 10.000 s, µM
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_019.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_020.png
         :alt: 4.000 s, 5.000 s, 6.000 s, 7.000 s, 8.000 s, 9.000 s, 10.000 s, µM
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_020.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <MNEFigure size 1050x220 with 8 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 301-302

And we can plot the comparison at a single time point for two conditions.

.. GENERATED FROM PYTHON SOURCE LINES 302-331

.. code-block:: Python


    fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(9, 5),
                             gridspec_kw=dict(width_ratios=[1, 1, 1, 0.1]))
    vlim, ts = (-8, 8), 9.0

    evoked_left = epochs['Tapping/Left'].average()
    evoked_right = epochs['Tapping/Right'].average()

    evoked_left.plot_topomap(ch_type='hbo', times=ts, axes=axes[0, 0],
                             vlim=vlim, colorbar=False, **topomap_args)
    evoked_left.plot_topomap(ch_type='hbr', times=ts, axes=axes[1, 0],
                             vlim=vlim, colorbar=False, **topomap_args)
    evoked_right.plot_topomap(ch_type='hbo', times=ts, axes=axes[0, 1],
                              vlim=vlim, colorbar=False, **topomap_args)
    evoked_right.plot_topomap(ch_type='hbr', times=ts, axes=axes[1, 1],
                              vlim=vlim, colorbar=False, **topomap_args)

    evoked_diff = mne.combine_evoked([evoked_left, evoked_right], weights=[1, -1])

    evoked_diff.plot_topomap(ch_type='hbo', times=ts, axes=axes[0, 2:],
                             vlim=vlim, colorbar=True, **topomap_args)
    evoked_diff.plot_topomap(ch_type='hbr', times=ts, axes=axes[1, 2:],
                             vlim=vlim, colorbar=True, **topomap_args)

    for column, condition in enumerate(
            ['Tapping Left', 'Tapping Right', 'Left-Right']):
        for row, chroma in enumerate(['HbO', 'HbR']):
            axes[row, column].set_title('{}: {}'.format(chroma, condition))




.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_021.png
   :alt: HbO: Tapping Left, HbO: Tapping Right, HbO: Left-Right, µM, HbR: Tapping Left, HbR: Tapping Right, HbR: Left-Right, µM
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_021.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 332-334

Lastly, we can also look at the individual waveforms to see what is
driving the topographic plot above.

.. GENERATED FROM PYTHON SOURCE LINES 334-345

.. code-block:: Python


    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(6, 4))
    mne.viz.plot_evoked_topo(epochs['Left'].average(picks='hbo'), color='b',
                             axes=axes, legend=False)
    mne.viz.plot_evoked_topo(epochs['Right'].average(picks='hbo'), color='r',
                             axes=axes, legend=False)

    # Tidy the legend:
    leg_lines = [line for line in axes.lines if line.get_c() == 'b'][:1]
    leg_lines.append([line for line in axes.lines if line.get_c() == 'r'][0])
    fig.legend(leg_lines, ['Left', 'Right'], loc='lower right')



.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_022.png
   :alt: plot 15 waveform
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_022.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <matplotlib.legend.Legend object at 0x7ff2a88b2d40>




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 23.822 seconds)

**Estimated memory usage:**  23 MB


.. _sphx_glr_download_auto_examples_general_plot_15_waveform.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/mne-tools/mne-nirs/gh-pages?filepath=stable/notebooks/auto_examples/general/plot_15_waveform.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_15_waveform.ipynb <plot_15_waveform.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_15_waveform.py <plot_15_waveform.py>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
