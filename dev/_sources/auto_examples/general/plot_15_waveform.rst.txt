
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/general/plot_15_waveform.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_general_plot_15_waveform.py>`
        to download the full example code. or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_general_plot_15_waveform.py:


.. _tut-fnirs-processing:

Waveform Averaging Analysis
===========================

.. note:: This tutorial is a mirror of the
          (`MNE tutorial <https://mne.tools/stable/auto_tutorials/preprocessing/plot_70_fnirs_processing.html>`__),
          and is reproduced in MNE-NIRS for convenience and so that all
          relevant material is easily accessible to users.

This tutorial covers how to convert functional near-infrared spectroscopy
(fNIRS) data from raw measurements to relative oxyhaemoglobin (HbO) and
deoxyhaemoglobin (HbR) concentration, view the average waveform, and
topographic representation of the response.

Here we will work with the :ref:`fNIRS motor data <mne:fnirs-motor-dataset>`.

.. GENERATED FROM PYTHON SOURCE LINES 19-25

.. code-block:: Python

    # sphinx_gallery_thumbnail_number = 14

    # Authors: Robert Luke <mail@robertluke.net>
    #
    # License: BSD (3-clause)








.. GENERATED FROM PYTHON SOURCE LINES 26-40

.. code-block:: Python


    import os.path as op
    from itertools import compress

    import matplotlib.pyplot as plt
    import mne
    import numpy as np

    fnirs_data_folder = mne.datasets.fnirs_motor.data_path()
    fnirs_cw_amplitude_dir = op.join(fnirs_data_folder, "Participant-1")
    raw_intensity = mne.io.read_raw_nirx(fnirs_cw_amplitude_dir, verbose=True)
    raw_intensity.load_data()






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Loading /home/circleci/mne_data/MNE-fNIRS-motor-data/Participant-1
    Reading 0 ... 23238  =      0.000 ...  2974.464 secs...


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <script type="text/javascript">
        const toggleVisibility = (className) => {

      const elements = document.querySelectorAll(`.${className}`)

      elements.forEach(element => {
        if (element.classList.contains('repr-section-header')) {
          // Don't collapse the section header row.
           return
        }
        if (element.classList.contains('repr-element-collapsed')) {
          // Force a reflow to ensure the display change takes effect before removing the class
          element.classList.remove('repr-element-collapsed')
          element.offsetHeight // This forces the browser to recalculate layout
          element.classList.remove('repr-element-faded')
        } else {
          // Start transition to hide the element
          element.classList.add('repr-element-faded')
          element.addEventListener('transitionend', handler = (e) => {
            if (e.propertyName === 'opacity' && getComputedStyle(element).opacity === '0.2') {
              element.classList.add('repr-element-collapsed')
              element.removeEventListener('transitionend', handler)
            }
          });
        }
      });

      // Take care of button (adjust caret)
      const button = document.querySelectorAll(`.repr-section-header.${className} > th.repr-section-toggle-col > button`)[0]
      button.classList.toggle('collapsed')

      // Take care of the tooltip of the section header row
      const sectionHeaderRow = document.querySelectorAll(`tr.repr-section-header.${className}`)[0]
      sectionHeaderRow.classList.toggle('collapsed')
      sectionHeaderRow.title = sectionHeaderRow.title === 'Hide section' ? 'Show section' : 'Hide section'
    }
    </script>

    <style type="text/css">
        table.repr.table.table-hover.table-striped.table-sm.table-responsive.small {
      /* Don't make rows wider than they need to be. */
      display: inline;
    }

    table > tbody > tr.repr-element > td {
      /* Apply a tighter layout to the table cells. */
      padding-top: 0.1rem;
      padding-bottom: 0.1rem;
      padding-right: 1rem;
    }

    table > tbody > tr > td.repr-section-toggle-col {
      /* Remove background and border of the first cell in every row
         (this row is only used for the collapse / uncollapse caret)

         TODO: Need to find a good solution for VS Code that works in both
               light and dark mode. */
      border-color: transparent;
      --bs-table-accent-bg: transparent;
    }

    tr.repr-section-header {
      /* Remove stripes from section header rows */
      background-color: transparent;
      border-color: transparent;
      --bs-table-striped-bg: transparent;
      cursor: pointer;
    }

    tr.repr-section-header > th {
      text-align: left !important;
      vertical-align: middle;
    }

    .repr-element, tr.repr-element > td {
      opacity: 1;
      text-align: left !important;
    }

    .repr-element-faded {
      transition: 0.3s ease;
      opacity: 0.2;
    }

    .repr-element-collapsed {
      display: none;
    }

    /* Collapse / uncollapse button and the caret it contains. */
    .repr-section-toggle-col button {
      cursor: pointer;
      width: 1rem;
      background-color: transparent;
      border-color: transparent;
    }

    span.collapse-uncollapse-caret {
      width: 1rem;
      height: 1rem;
      display: block;
      background-repeat: no-repeat;
      background-position: left;
      background-size: contain;
    }

    /* The collapse / uncollapse carets were copied from the free Font Awesome collection and adjusted. */

    /* Default to black carets for light mode */
    .repr-section-toggle-col > button.collapsed > span.collapse-uncollapse-caret {
      background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="black" d="M246.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-9.2-9.2-22.9-11.9-34.9-6.9s-19.8 16.6-19.8 29.6l0 256c0 12.9 7.8 24.6 19.8 29.6s25.7 2.2 34.9-6.9l128-128z"/></svg>');
    }

    .repr-section-toggle-col
      > button:not(.collapsed)
      > span.collapse-uncollapse-caret {
      background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="black" d="M137.4 374.6c12.5 12.5 32.8 12.5 45.3 0l128-128c9.2-9.2 11.9-22.9 6.9-34.9s-16.6-19.8-29.6-19.8L32 192c-12.9 0-24.6 7.8-29.6 19.8s-2.2 25.7 6.9 34.9l128 128z"/></svg>');
    }

    /* Use white carets for dark mode */
    @media (prefers-color-scheme: dark) {
      .repr-section-toggle-col > button.collapsed > span.collapse-uncollapse-caret {
        background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="white" d="M246.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-9.2-9.2-22.9-11.9-34.9-6.9s-19.8 16.6-19.8 29.6l0 256c0 12.9 7.8 24.6 19.8 29.6s25.7 2.2 34.9-6.9l128-128z"/></svg>');
      }

      .repr-section-toggle-col
        > button:not(.collapsed)
        > span.collapse-uncollapse-caret {
        background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="white" d="M137.4 374.6c12.5 12.5 32.8 12.5 45.3 0l128-128c9.2-9.2 11.9-22.9 6.9-34.9s-16.6-19.8-29.6-19.8L32 192c-12.9 0-24.6 7.8-29.6 19.8s-2.2 25.7 6.9 34.9l128 128z"/></svg>');
      }
    }

    .channel-names-btn {
      padding: 0;
      border: none;
      background: none;
      text-decoration: underline;
      text-decoration-style: dashed;
      cursor: pointer;
      color: #0d6efd;
    }

    .channel-names-btn:hover {
      color: #0a58ca;
    }
    </style>



    <table class="repr table table-hover table-striped table-sm table-responsive small">
    







    <tr class="repr-section-header general-9e58bf3f-f864-4ecb-a9b0-73fe7c57b35a"  title="Hide section" 
        onclick="toggleVisibility('general-9e58bf3f-f864-4ecb-a9b0-73fe7c57b35a')">
        <th class="repr-section-toggle-col">
            <button>
            
                <span class="collapse-uncollapse-caret"></span>
            </button>
        </th>
        <th colspan="2">
            <strong>General</strong>
        </th>
    </tr>

    <tr class="repr-element general-9e58bf3f-f864-4ecb-a9b0-73fe7c57b35a ">
        <td class="repr-section-toggle-col"></td>
        <td>Filename(s)</td>
        <td>
        
            Participant-1
        
        
        </td>
    </tr>

    <tr class="repr-element general-9e58bf3f-f864-4ecb-a9b0-73fe7c57b35a ">
        <td class="repr-section-toggle-col"></td>
        <td>MNE object type</td>
        <td>RawNIRX</td>
    </tr>
    <tr class="repr-element general-9e58bf3f-f864-4ecb-a9b0-73fe7c57b35a ">
        <td class="repr-section-toggle-col"></td>
        <td>Measurement date</td>
    
        <td>2019-11-02 at 13:16:16 UTC</td>
    
    </tr>
    <tr class="repr-element general-9e58bf3f-f864-4ecb-a9b0-73fe7c57b35a ">
        <td class="repr-section-toggle-col"></td>
        <td>Participant</td>
    
    
        <td>P1</td>
    
    
    </tr>
    <tr class="repr-element general-9e58bf3f-f864-4ecb-a9b0-73fe7c57b35a ">
        <td class="repr-section-toggle-col"></td>
        <td>Experimenter</td>
    
        <td>Unknown</td>
    
    </tr>
    







    <tr class="repr-section-header acquisition-3eaad69e-2f21-465b-8695-39f4176699e0" 
        title="Hide section"  onclick="toggleVisibility('acquisition-3eaad69e-2f21-465b-8695-39f4176699e0')">
        <th class="repr-section-toggle-col">
            <button>
            
                <span class="collapse-uncollapse-caret"></span>
            </button>
        </th>
        <th colspan="2">
            <strong>Acquisition</strong>
        </th>
    </tr>

    <tr class="repr-element acquisition-3eaad69e-2f21-465b-8695-39f4176699e0 ">
        <td class="repr-section-toggle-col"></td>
        <td>Duration</td>
        <td>00:49:35 (HH:MM:SS)</td>
    </tr>








    <tr class="repr-element acquisition-3eaad69e-2f21-465b-8695-39f4176699e0 ">
        <td class="repr-section-toggle-col"></td>
        <td>Sampling frequency</td>
        <td>7.81 Hz</td>
    </tr>


    <tr class="repr-element acquisition-3eaad69e-2f21-465b-8695-39f4176699e0 ">
        <td class="repr-section-toggle-col"></td>
        <td>Time points</td>
        <td>23,239</td>
    </tr>


    







    <tr class="repr-section-header channels-8a8cf87d-76cc-49a9-b9c4-9b55e32b81b9"  title="Hide section" 
        onclick="toggleVisibility('channels-8a8cf87d-76cc-49a9-b9c4-9b55e32b81b9')">
        <th class="repr-section-toggle-col">
            <button>
            
                <span class="collapse-uncollapse-caret"></span>
            </button>
        </th>
        <th colspan="2">
            <strong>Channels</strong>
        </th>
    </tr>


    <tr class="repr-element channels-8a8cf87d-76cc-49a9-b9c4-9b55e32b81b9 ">
        <td class="repr-section-toggle-col"></td>
        <td>fNIRS (CW amplitude)</td>
        <td>
            <button class="channel-names-btn" onclick="alert('Good fNIRS (CW amplitude):\n\nS1_D1&nbsp;760, S1_D1&nbsp;850, S1_D2&nbsp;760, S1_D2&nbsp;850, S1_D3&nbsp;760, S1_D3&nbsp;850, S1_D9&nbsp;760, S1_D9&nbsp;850, S2_D1&nbsp;760, S2_D1&nbsp;850, S2_D3&nbsp;760, S2_D3&nbsp;850, S2_D4&nbsp;760, S2_D4&nbsp;850, S2_D10&nbsp;760, S2_D10&nbsp;850, S3_D2&nbsp;760, S3_D2&nbsp;850, S3_D3&nbsp;760, S3_D3&nbsp;850, S3_D11&nbsp;760, S3_D11&nbsp;850, S4_D3&nbsp;760, S4_D3&nbsp;850, S4_D4&nbsp;760, S4_D4&nbsp;850, S4_D12&nbsp;760, S4_D12&nbsp;850, S5_D5&nbsp;760, S5_D5&nbsp;850, S5_D6&nbsp;760, S5_D6&nbsp;850, S5_D7&nbsp;760, S5_D7&nbsp;850, S5_D13&nbsp;760, S5_D13&nbsp;850, S6_D5&nbsp;760, S6_D5&nbsp;850, S6_D7&nbsp;760, S6_D7&nbsp;850, S6_D8&nbsp;760, S6_D8&nbsp;850, S6_D14&nbsp;760, S6_D14&nbsp;850, S7_D6&nbsp;760, S7_D6&nbsp;850, S7_D7&nbsp;760, S7_D7&nbsp;850, S7_D15&nbsp;760, S7_D15&nbsp;850, S8_D7&nbsp;760, S8_D7&nbsp;850, S8_D8&nbsp;760, S8_D8&nbsp;850, S8_D16&nbsp;760, S8_D16&nbsp;850')" title="(Click to open in popup)&#13;&#13;S1_D1&nbsp;760, S1_D1&nbsp;850, S1_D2&nbsp;760, S1_D2&nbsp;850, S1_D3&nbsp;760, S1_D3&nbsp;850, S1_D9&nbsp;760, S1_D9&nbsp;850, S2_D1&nbsp;760, S2_D1&nbsp;850, S2_D3&nbsp;760, S2_D3&nbsp;850, S2_D4&nbsp;760, S2_D4&nbsp;850, S2_D10&nbsp;760, S2_D10&nbsp;850, S3_D2&nbsp;760, S3_D2&nbsp;850, S3_D3&nbsp;760, S3_D3&nbsp;850, S3_D11&nbsp;760, S3_D11&nbsp;850, S4_D3&nbsp;760, S4_D3&nbsp;850, S4_D4&nbsp;760, S4_D4&nbsp;850, S4_D12&nbsp;760, S4_D12&nbsp;850, S5_D5&nbsp;760, S5_D5&nbsp;850, S5_D6&nbsp;760, S5_D6&nbsp;850, S5_D7&nbsp;760, S5_D7&nbsp;850, S5_D13&nbsp;760, S5_D13&nbsp;850, S6_D5&nbsp;760, S6_D5&nbsp;850, S6_D7&nbsp;760, S6_D7&nbsp;850, S6_D8&nbsp;760, S6_D8&nbsp;850, S6_D14&nbsp;760, S6_D14&nbsp;850, S7_D6&nbsp;760, S7_D6&nbsp;850, S7_D7&nbsp;760, S7_D7&nbsp;850, S7_D15&nbsp;760, S7_D15&nbsp;850, S8_D7&nbsp;760, S8_D7&nbsp;850, S8_D8&nbsp;760, S8_D8&nbsp;850, S8_D16&nbsp;760, S8_D16&nbsp;850">
                56
            </button>

        
        </td>
    </tr>


    <tr class="repr-element channels-8a8cf87d-76cc-49a9-b9c4-9b55e32b81b9 ">
        <td class="repr-section-toggle-col"></td>
        <td>Head & sensor digitization</td>
    
        <td>31 points</td>
    
    </tr>
    







    <tr class="repr-section-header filters-2da1fe38-bc1f-4a30-854b-8d62fe8fa380"  title="Hide section" 
        onclick="toggleVisibility('filters-2da1fe38-bc1f-4a30-854b-8d62fe8fa380')">
        <th class="repr-section-toggle-col">
            <button>
            
                <span class="collapse-uncollapse-caret"></span>
            </button>
        </th>
        <th colspan="2">
            <strong>Filters</strong>
        </th>
    </tr>

    <tr class="repr-element filters-2da1fe38-bc1f-4a30-854b-8d62fe8fa380 ">
        <td class="repr-section-toggle-col"></td>
        <td>Highpass</td>
        <td>0.00 Hz</td>
    </tr>


    <tr class="repr-element filters-2da1fe38-bc1f-4a30-854b-8d62fe8fa380 ">
        <td class="repr-section-toggle-col"></td>
        <td>Lowpass</td>
        <td>3.91 Hz</td>
    </tr>


    </table>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 41-49

Providing more meaningful annotation information
------------------------------------------------

First, we attribute more meaningful names to the trigger codes which are
stored as annotations. Second, we include information about the duration of
each stimulus, which was 5 seconds for all conditions in this experiment.
Third, we remove the trigger code 15, which signaled the start and end
of the experiment and is not relevant to our analysis.

.. GENERATED FROM PYTHON SOURCE LINES 49-58

.. code-block:: Python


    raw_intensity.annotations.set_durations(5)
    raw_intensity.annotations.rename(
        {"1.0": "Control", "2.0": "Tapping/Left", "3.0": "Tapping/Right"}
    )
    unwanted = np.nonzero(raw_intensity.annotations.description == "15.0")
    raw_intensity.annotations.delete(unwanted)









.. GENERATED FROM PYTHON SOURCE LINES 59-67

Viewing location of sensors over brain surface
----------------------------------------------

Here we validate that the location of sources-detector pairs and channels
are in the expected locations. Source-detector pairs are shown as lines
between the optodes, channels (the mid point of source-detector pairs) are
optionally shown as orange dots. Source are optionally shown as red dots and
detectors as black.

.. GENERATED FROM PYTHON SOURCE LINES 67-80

.. code-block:: Python


    subjects_dir = op.join(mne.datasets.sample.data_path(), "subjects")

    brain = mne.viz.Brain(
        "fsaverage", subjects_dir=subjects_dir, background="w", cortex="0.5"
    )
    brain.add_sensors(
        raw_intensity.info,
        trans="fsaverage",
        fnirs=["channels", "pairs", "sources", "detectors"],
    )
    brain.show_view(azimuth=20, elevation=60, distance=400)




.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_001.png
   :alt: plot 15 waveform
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Channel types:: fnirs_cw_amplitude: 56




.. GENERATED FROM PYTHON SOURCE LINES 81-88

Selecting channels appropriate for detecting neural responses
-------------------------------------------------------------

First we remove channels that are too close together (short channels) to
detect a neural response (less than 1 cm distance between optodes).
These short channels can be seen in the figure above.
To achieve this we pick all the channels that are not considered to be short.

.. GENERATED FROM PYTHON SOURCE LINES 88-99

.. code-block:: Python


    picks = mne.pick_types(raw_intensity.info, meg=False, fnirs=True)
    dists = mne.preprocessing.nirs.source_detector_distances(
        raw_intensity.info, picks=picks
    )
    raw_intensity.pick(picks[dists > 0.01])
    raw_intensity.plot(
        n_channels=len(raw_intensity.ch_names), duration=500, show_scrollbars=False
    )





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_002.png
   :alt: Raw plot
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <mne_qt_browser._pg_figure.MNEQtBrowser object at 0x7fe6b277f6d0>



.. GENERATED FROM PYTHON SOURCE LINES 100-104

Converting from raw intensity to optical density
------------------------------------------------

The raw intensity values are then converted to optical density.

.. GENERATED FROM PYTHON SOURCE LINES 104-109

.. code-block:: Python


    raw_od = mne.preprocessing.nirs.optical_density(raw_intensity)
    raw_od.plot(n_channels=len(raw_od.ch_names), duration=500, show_scrollbars=False)





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_003.png
   :alt: Raw plot
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <mne_qt_browser._pg_figure.MNEQtBrowser object at 0x7fe6b2759360>



.. GENERATED FROM PYTHON SOURCE LINES 110-121

Evaluating the quality of the data
----------------------------------

At this stage we can quantify the quality of the coupling
between the scalp and the optodes using the scalp coupling index. This
method looks for the presence of a prominent synchronous signal in the
frequency range of cardiac signals across both photodetected signals.

In this example the data is clean and the coupling is good for all
channels, so we will not mark any channels as bad based on the scalp
coupling index.

.. GENERATED FROM PYTHON SOURCE LINES 121-128

.. code-block:: Python


    sci = mne.preprocessing.nirs.scalp_coupling_index(raw_od)
    fig, ax = plt.subplots()
    ax.hist(sci)
    ax.set(xlabel="Scalp Coupling Index", ylabel="Count", xlim=[0, 1])





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_004.png
   :alt: plot 15 waveform
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_004.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    [Text(0.5, 23.52222222222222, 'Scalp Coupling Index'), Text(47.097222222222214, 0.5, 'Count'), (0.0, 1.0)]



.. GENERATED FROM PYTHON SOURCE LINES 129-131

In this example we will mark all channels with a SCI less than 0.5 as bad
(this dataset is quite clean, so no channels are marked as bad).

.. GENERATED FROM PYTHON SOURCE LINES 131-135

.. code-block:: Python


    raw_od.info["bads"] = list(compress(raw_od.ch_names, sci < 0.5))









.. GENERATED FROM PYTHON SOURCE LINES 136-142

At this stage it is appropriate to inspect your data
(for instructions on how to use the interactive data visualisation tool
see :ref:`tut-visualize-raw`)
to ensure that channels with poor scalp coupling have been removed.
If your data contains lots of artifacts you may decide to apply
artifact reduction techniques as described in :ref:`ex-fnirs-artifacts`.

.. GENERATED FROM PYTHON SOURCE LINES 145-150

Converting from optical density to haemoglobin
----------------------------------------------

Next we convert the optical density data to haemoglobin concentration using
the modified Beer-Lambert law.

.. GENERATED FROM PYTHON SOURCE LINES 150-155

.. code-block:: Python


    raw_haemo = mne.preprocessing.nirs.beer_lambert_law(raw_od, ppf=0.1)
    raw_haemo.plot(n_channels=len(raw_haemo.ch_names), duration=500, show_scrollbars=False)





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_005.png
   :alt: Raw plot
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_005.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <mne_qt_browser._pg_figure.MNEQtBrowser object at 0x7fe7042c4e50>



.. GENERATED FROM PYTHON SOURCE LINES 156-164

Removing heart rate from signal
-------------------------------

The haemodynamic response has frequency content predominantly below 0.5 Hz.
An increase in activity around 1 Hz can be seen in the data that is due to
the person's heart beat and is unwanted. So we use a low pass filter to
remove this. A high pass filter is also included to remove slow drifts
in the data.

.. GENERATED FROM PYTHON SOURCE LINES 164-171

.. code-block:: Python


    fig = raw_haemo.compute_psd().plot(average=True, amplitude=False)
    fig.suptitle("Before filtering", weight="bold", size="x-large")
    raw_haemo = raw_haemo.filter(0.05, 0.7, h_trans_bandwidth=0.2, l_trans_bandwidth=0.02)
    fig = raw_haemo.compute_psd().plot(average=True, amplitude=False)
    fig.suptitle("After filtering", weight="bold", size="x-large")




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_006.png
         :alt: Before filtering, Oxyhemoglobin, Deoxyhemoglobin
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_006.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_007.png
         :alt: After filtering, Oxyhemoglobin, Deoxyhemoglobin
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_007.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Effective window size : 262.144 (s)
    Plotting power spectral density (dB=True).
    Filtering raw data in 1 contiguous segment
    Setting up band-pass filter from 0.05 - 0.7 Hz

    FIR filter parameters
    ---------------------
    Designing a one-pass, zero-phase, non-causal bandpass filter:
    - Windowed time-domain design (firwin) method
    - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation
    - Lower passband edge: 0.05
    - Lower transition bandwidth: 0.02 Hz (-6 dB cutoff frequency: 0.04 Hz)
    - Upper passband edge: 0.70 Hz
    - Upper transition bandwidth: 0.20 Hz (-6 dB cutoff frequency: 0.80 Hz)
    - Filter length: 1291 samples (165.248 s)

    [Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s
    Effective window size : 262.144 (s)
    Plotting power spectral density (dB=True).

    Text(0.5, 0.993055, 'After filtering')



.. GENERATED FROM PYTHON SOURCE LINES 172-181

Extract epochs
--------------

Now that the signal has been converted to relative haemoglobin concentration,
and the unwanted heart rate component has been removed, we can extract epochs
related to each of the experimental conditions.

First we extract the events of interest and visualise them to ensure they are
correct.

.. GENERATED FROM PYTHON SOURCE LINES 181-186

.. code-block:: Python


    events, event_dict = mne.events_from_annotations(raw_haemo)
    fig = mne.viz.plot_events(events, event_id=event_dict, sfreq=raw_haemo.info["sfreq"])





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_008.png
   :alt: plot 15 waveform
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_008.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Used Annotations descriptions: [np.str_('Control'), np.str_('Tapping/Left'), np.str_('Tapping/Right')]




.. GENERATED FROM PYTHON SOURCE LINES 187-190

Next we define the range of our epochs, the rejection criteria,
baseline correction, and extract the epochs. We visualise the log of which
epochs were dropped.

.. GENERATED FROM PYTHON SOURCE LINES 190-211

.. code-block:: Python


    reject_criteria = dict(hbo=80e-6)
    tmin, tmax = -5, 15

    epochs = mne.Epochs(
        raw_haemo,
        events,
        event_id=event_dict,
        tmin=tmin,
        tmax=tmax,
        reject=reject_criteria,
        reject_by_annotation=True,
        proj=True,
        baseline=(None, 0),
        preload=True,
        detrend=None,
        verbose=True,
    )
    epochs.plot_drop_log()





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_009.png
   :alt: 6 of 90 epochs removed (6.7%)
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_009.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Not setting metadata
    90 matching events found
    Setting baseline interval to [-4.992, 0.0] s
    Applying baseline correction (mode: mean)
    0 projection items activated
    Using data from preloaded Raw for 90 events and 157 original time points ...
        Rejecting  epoch based on HBO : ['S4_D4 hbo']
        Rejecting  epoch based on HBO : ['S4_D4 hbo', 'S8_D8 hbo']
        Rejecting  epoch based on HBO : ['S4_D4 hbo']
        Rejecting  epoch based on HBO : ['S4_D4 hbo', 'S8_D8 hbo']
        Rejecting  epoch based on HBO : ['S1_D1 hbo', 'S3_D3 hbo', 'S4_D4 hbo', 'S7_D6 hbo', 'S7_D7 hbo', 'S8_D8 hbo']
        Rejecting  epoch based on HBO : ['S4_D4 hbo', 'S6_D8 hbo', 'S8_D8 hbo']
    6 bad epochs dropped

    <Figure size 640x480 with 1 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 212-220

View consistency of responses across trials
-------------------------------------------

Now we can view the haemodynamic response for our tapping condition.
We visualise the response for both the oxy- and deoxyhaemoglobin, and
observe the expected peak in HbO at around 6 seconds consistently across
trials, and the consistent dip in HbR that is slightly delayed relative to
the HbO peak.

.. GENERATED FROM PYTHON SOURCE LINES 220-229

.. code-block:: Python


    epochs["Tapping"].plot_image(
        combine="mean",
        vmin=-30,
        vmax=30,
        ts_args=dict(ylim=dict(hbo=[-15, 15], hbr=[-15, 15])),
    )





.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_010.png
         :alt: Deoxyhemoglobin (mean), µM
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_010.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_011.png
         :alt: Oxyhemoglobin (mean), µM
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_011.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Not setting metadata
    55 matching events found
    No baseline correction applied
    0 projection items activated
    Not setting metadata
    55 matching events found
    No baseline correction applied
    0 projection items activated
    combining channels using "mean"
    combining channels using "mean"

    [<Figure size 640x480 with 3 Axes>, <Figure size 640x480 with 3 Axes>]



.. GENERATED FROM PYTHON SOURCE LINES 230-232

We can also view the epoched data for the control condition and observe
that it does not show the expected morphology.

.. GENERATED FROM PYTHON SOURCE LINES 232-241

.. code-block:: Python


    epochs["Control"].plot_image(
        combine="mean",
        vmin=-30,
        vmax=30,
        ts_args=dict(ylim=dict(hbo=[-15, 15], hbr=[-15, 15])),
    )





.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_012.png
         :alt: Deoxyhemoglobin (mean), µM
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_012.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_013.png
         :alt: Oxyhemoglobin (mean), µM
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_013.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Not setting metadata
    29 matching events found
    No baseline correction applied
    0 projection items activated
    Not setting metadata
    29 matching events found
    No baseline correction applied
    0 projection items activated
    combining channels using "mean"
    combining channels using "mean"

    [<Figure size 640x480 with 3 Axes>, <Figure size 640x480 with 3 Axes>]



.. GENERATED FROM PYTHON SOURCE LINES 242-248

View consistency of responses across channels
---------------------------------------------

Similarly we can view how consistent the response is across the optode
pairs that we selected. All the channels in this data are located over the
motor cortex, and all channels show a similar pattern in the data.

.. GENERATED FROM PYTHON SOURCE LINES 248-258

.. code-block:: Python


    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 6))
    clims = dict(hbo=[-20, 20], hbr=[-20, 20])
    epochs["Control"].average().plot_image(axes=axes[:, 0], clim=clims)
    epochs["Tapping"].average().plot_image(axes=axes[:, 1], clim=clims)
    for column, condition in enumerate(["Control", "Tapping"]):
        for ax in axes[:, column]:
            ax.set_title(f"{condition}: {ax.get_title()}")





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_014.png
   :alt: Control: Oxyhemoglobin (20 channels), Tapping: Oxyhemoglobin (20 channels), Control: Deoxyhemoglobin (20 channels), Tapping: Deoxyhemoglobin (20 channels), µM, µM, µM, µM
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_014.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 259-265

Plot standard fNIRS response image
----------------------------------

Next we generate the most common visualisation of fNIRS data: plotting
both the HbO and HbR on the same figure to illustrate the relation between
the two signals.

.. GENERATED FROM PYTHON SOURCE LINES 265-285

.. code-block:: Python


    evoked_dict = {
        "Tapping/HbO": epochs["Tapping"].average(picks="hbo"),
        "Tapping/HbR": epochs["Tapping"].average(picks="hbr"),
        "Control/HbO": epochs["Control"].average(picks="hbo"),
        "Control/HbR": epochs["Control"].average(picks="hbr"),
    }

    # Rename channels until the encoding of frequency in ch_name is fixed
    for condition in evoked_dict:
        evoked_dict[condition].rename_channels(lambda x: x[:-4])

    color_dict = dict(HbO="#AA3377", HbR="b")
    styles_dict = dict(Control=dict(linestyle="dashed"))

    mne.viz.plot_compare_evokeds(
        evoked_dict, combine="mean", ci=0.95, colors=color_dict, styles=styles_dict
    )





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_015.png
   :alt: plot 15 waveform
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_015.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    combining channels using "mean"
    combining channels using "mean"
    combining channels using "mean"
    combining channels using "mean"

    [<Figure size 800x600 with 1 Axes>]



.. GENERATED FROM PYTHON SOURCE LINES 286-290

View topographic representation of activity
-------------------------------------------

Next we view how the topographic activity changes throughout the response.

.. GENERATED FROM PYTHON SOURCE LINES 290-298

.. code-block:: Python


    times = np.arange(-3.5, 13.2, 3.0)
    topomap_args = dict(extrapolate="local")
    epochs["Tapping"].average(picks="hbo").plot_joint(
        times=times, topomap_args=topomap_args
    )





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_016.png
   :alt: Oxyhemoglobin (20 channels), -3.500 s, -0.500 s, 2.500 s, 5.500 s, 8.500 s, 11.500 s
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_016.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    No projector specified for this dataset. Please consider the method self.add_proj.

    <Figure size 800x420 with 9 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 299-304

Compare tapping of left and right hands
---------------------------------------

Finally we generate topo maps for the left and right conditions to view
the location of activity. First we visualise the HbO activity.

.. GENERATED FROM PYTHON SOURCE LINES 304-309

.. code-block:: Python


    times = np.arange(4.0, 11.0, 1.0)
    epochs["Tapping/Left"].average(picks="hbo").plot_topomap(times=times, **topomap_args)
    epochs["Tapping/Right"].average(picks="hbo").plot_topomap(times=times, **topomap_args)




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_017.png
         :alt: 4.000 s, 5.000 s, 6.000 s, 7.000 s, 8.000 s, 9.000 s, 10.000 s, µM
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_017.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_018.png
         :alt: 4.000 s, 5.000 s, 6.000 s, 7.000 s, 8.000 s, 9.000 s, 10.000 s, µM
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_018.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <MNEFigure size 1050x220 with 8 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 310-311

And we also view the HbR activity for the two conditions.

.. GENERATED FROM PYTHON SOURCE LINES 311-315

.. code-block:: Python


    epochs["Tapping/Left"].average(picks="hbr").plot_topomap(times=times, **topomap_args)
    epochs["Tapping/Right"].average(picks="hbr").plot_topomap(times=times, **topomap_args)




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_019.png
         :alt: 4.000 s, 5.000 s, 6.000 s, 7.000 s, 8.000 s, 9.000 s, 10.000 s, µM
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_019.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_020.png
         :alt: 4.000 s, 5.000 s, 6.000 s, 7.000 s, 8.000 s, 9.000 s, 10.000 s, µM
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_020.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <MNEFigure size 1050x220 with 8 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 316-317

And we can plot the comparison at a single time point for two conditions.

.. GENERATED FROM PYTHON SOURCE LINES 317-352

.. code-block:: Python


    fig, axes = plt.subplots(
        nrows=2, ncols=4, figsize=(9, 5), gridspec_kw=dict(width_ratios=[1, 1, 1, 0.1])
    )
    vlim, ts = (-8, 8), 9.0

    evoked_left = epochs["Tapping/Left"].average()
    evoked_right = epochs["Tapping/Right"].average()

    evoked_left.plot_topomap(
        ch_type="hbo", times=ts, axes=axes[0, 0], vlim=vlim, colorbar=False, **topomap_args
    )
    evoked_left.plot_topomap(
        ch_type="hbr", times=ts, axes=axes[1, 0], vlim=vlim, colorbar=False, **topomap_args
    )
    evoked_right.plot_topomap(
        ch_type="hbo", times=ts, axes=axes[0, 1], vlim=vlim, colorbar=False, **topomap_args
    )
    evoked_right.plot_topomap(
        ch_type="hbr", times=ts, axes=axes[1, 1], vlim=vlim, colorbar=False, **topomap_args
    )

    evoked_diff = mne.combine_evoked([evoked_left, evoked_right], weights=[1, -1])

    evoked_diff.plot_topomap(
        ch_type="hbo", times=ts, axes=axes[0, 2:], vlim=vlim, colorbar=True, **topomap_args
    )
    evoked_diff.plot_topomap(
        ch_type="hbr", times=ts, axes=axes[1, 2:], vlim=vlim, colorbar=True, **topomap_args
    )

    for column, condition in enumerate(["Tapping Left", "Tapping Right", "Left-Right"]):
        for row, chroma in enumerate(["HbO", "HbR"]):
            axes[row, column].set_title(f"{chroma}: {condition}")




.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_021.png
   :alt: HbO: Tapping Left, HbO: Tapping Right, HbO: Left-Right, µM, HbR: Tapping Left, HbR: Tapping Right, HbR: Left-Right, µM
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_021.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 353-355

Lastly, we can also look at the individual waveforms to see what is
driving the topographic plot above.

.. GENERATED FROM PYTHON SOURCE LINES 355-368

.. code-block:: Python


    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(6, 4))
    mne.viz.plot_evoked_topo(
        epochs["Left"].average(picks="hbo"), color="b", axes=axes, legend=False
    )
    mne.viz.plot_evoked_topo(
        epochs["Right"].average(picks="hbo"), color="r", axes=axes, legend=False
    )

    # Tidy the legend:
    leg_lines = [line for line in axes.lines if line.get_c() == "b"][:1]
    leg_lines.append([line for line in axes.lines if line.get_c() == "r"][0])
    fig.legend(leg_lines, ["Left", "Right"], loc="lower right")



.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_022.png
   :alt: plot 15 waveform
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_022.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <matplotlib.legend.Legend object at 0x7fe704368730>




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 25.342 seconds)

**Estimated memory usage:**  463 MB


.. _sphx_glr_download_auto_examples_general_plot_15_waveform.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/mne-tools/mne-nirs/gh-pages?filepath=stable/notebooks/auto_examples/general/plot_15_waveform.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_15_waveform.ipynb <plot_15_waveform.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_15_waveform.py <plot_15_waveform.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_15_waveform.zip <plot_15_waveform.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
