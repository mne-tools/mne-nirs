
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/general/plot_15_waveform.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_general_plot_15_waveform.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_general_plot_15_waveform.py:


.. _tut-fnirs-processing:

Waveform Averaging Analysis
===========================

.. note:: This tutorial is a mirror of the
          (`MNE tutorial <https://mne.tools/stable/auto_tutorials/preprocessing/plot_70_fnirs_processing.html>`__),
          and is reproduced in MNE-NIRS for convenience and so that all
          relevant material is easily accessible to users.

This tutorial covers how to convert functional near-infrared spectroscopy
(fNIRS) data from raw measurements to relative oxyhaemoglobin (HbO) and
deoxyhaemoglobin (HbR) concentration, view the average waveform, and
topographic representation of the response.

Here we will work with the :ref:`fNIRS motor data <mne:fnirs-motor-dataset>`.

.. GENERATED FROM PYTHON SOURCE LINES 19-25

.. code-block:: default

    # sphinx_gallery_thumbnail_number = 14

    # Authors: Robert Luke <mail@robertluke.net>
    #
    # License: BSD (3-clause)








.. GENERATED FROM PYTHON SOURCE LINES 26-41

.. code-block:: default


    import os.path as op
    import numpy as np
    import matplotlib.pyplot as plt
    from itertools import compress

    import mne


    fnirs_data_folder = mne.datasets.fnirs_motor.data_path()
    fnirs_cw_amplitude_dir = op.join(fnirs_data_folder, 'Participant-1')
    raw_intensity = mne.io.read_raw_nirx(fnirs_cw_amplitude_dir, verbose=True)
    raw_intensity.load_data()






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Loading /home/circleci/mne_data/MNE-fNIRS-motor-data/Participant-1
    Reading 0 ... 23238  =      0.000 ...  2974.464 secs...


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <table class="table table-hover table-striped table-sm table-responsive small">
        <tr>
            <th>Measurement date</th>
        
            <td>November 02, 2019  13:16:16 GMT</td>
        
        </tr>
        <tr>
            <th>Experimenter</th>
        
            <td>Unknown</td>
        
        </tr>
            <th>Participant</th>
        
            
                <td>P1</td>
            
        
        </tr>
        <tr>
            <th>Digitized points</th>
        
            <td>31 points</td>
        
        </tr>
        <tr>
            <th>Good channels</th>
            <td>56 fNIRS (CW amplitude)</td>
        </tr>
        <tr>
            <th>Bad channels</th>
            <td>None</td>
        </tr>
        <tr>
            <th>EOG channels</th>
            <td>Not available</td>
        </tr>
        <tr>
            <th>ECG channels</th>
            <td>Not available</td>
    
        <tr>
            <th>Sampling frequency</th>
            <td>7.81 Hz</td>
        </tr>
    
    
        <tr>
            <th>Highpass</th>
            <td>0.00 Hz</td>
        </tr>
    
    
        <tr>
            <th>Lowpass</th>
            <td>3.91 Hz</td>
        </tr>
    
    
    
        <tr>
            <th>Filenames</th>
            <td>Participant-1</td>
        </tr>
    
        <tr>
            <th>Duration</th>
            <td>00:49:35 (HH:MM:SS)</td>
        </tr>
    </table>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 42-50

Providing more meaningful annotation information
------------------------------------------------

First, we attribute more meaningful names to the trigger codes which are
stored as annotations. Second, we include information about the duration of
each stimulus, which was 5 seconds for all conditions in this experiment.
Third, we remove the trigger code 15, which signaled the start and end
of the experiment and is not relevant to our analysis.

.. GENERATED FROM PYTHON SOURCE LINES 50-59

.. code-block:: default


    raw_intensity.annotations.set_durations(5)
    raw_intensity.annotations.rename({'1.0': 'Control',
                                      '2.0': 'Tapping/Left',
                                      '3.0': 'Tapping/Right'})
    unwanted = np.nonzero(raw_intensity.annotations.description == '15.0')
    raw_intensity.annotations.delete(unwanted)









.. GENERATED FROM PYTHON SOURCE LINES 60-68

Viewing location of sensors over brain surface
----------------------------------------------

Here we validate that the location of sources-detector pairs and channels
are in the expected locations. Source-detector pairs are shown as lines
between the optodes, channels (the mid point of source-detector pairs) are
optionally shown as orange dots. Source are optionally shown as red dots and
detectors as black.

.. GENERATED FROM PYTHON SOURCE LINES 68-78

.. code-block:: default


    subjects_dir = op.join(mne.datasets.sample.data_path(), 'subjects')

    brain = mne.viz.Brain(
        'fsaverage', subjects_dir=subjects_dir, background='w', cortex='0.5')
    brain.add_sensors(
        raw_intensity.info, trans='fsaverage',
        fnirs=['channels', 'pairs', 'sources', 'detectors'])
    brain.show_view(azimuth=20, elevation=60, distance=400)




.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_001.png
   :alt: plot 15 waveform
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Channel types:: fnirs_cw_amplitude: 56




.. GENERATED FROM PYTHON SOURCE LINES 79-86

Selecting channels appropriate for detecting neural responses
-------------------------------------------------------------

First we remove channels that are too close together (short channels) to
detect a neural response (less than 1 cm distance between optodes).
These short channels can be seen in the figure above.
To achieve this we pick all the channels that are not considered to be short.

.. GENERATED FROM PYTHON SOURCE LINES 86-95

.. code-block:: default


    picks = mne.pick_types(raw_intensity.info, meg=False, fnirs=True)
    dists = mne.preprocessing.nirs.source_detector_distances(
        raw_intensity.info, picks=picks)
    raw_intensity.pick(picks[dists > 0.01])
    raw_intensity.plot(n_channels=len(raw_intensity.ch_names),
                       duration=500, show_scrollbars=False)





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_002.png
   :alt: Raw plot
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <mne_qt_browser._pg_figure.MNEQtBrowser object at 0x7f106c53f8b0>



.. GENERATED FROM PYTHON SOURCE LINES 96-100

Converting from raw intensity to optical density
------------------------------------------------

The raw intensity values are then converted to optical density.

.. GENERATED FROM PYTHON SOURCE LINES 100-106

.. code-block:: default


    raw_od = mne.preprocessing.nirs.optical_density(raw_intensity)
    raw_od.plot(n_channels=len(raw_od.ch_names),
                duration=500, show_scrollbars=False)





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_003.png
   :alt: Raw plot
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <mne_qt_browser._pg_figure.MNEQtBrowser object at 0x7f104da8ec10>



.. GENERATED FROM PYTHON SOURCE LINES 107-118

Evaluating the quality of the data
----------------------------------

At this stage we can quantify the quality of the coupling
between the scalp and the optodes using the scalp coupling index. This
method looks for the presence of a prominent synchronous signal in the
frequency range of cardiac signals across both photodetected signals.

In this example the data is clean and the coupling is good for all
channels, so we will not mark any channels as bad based on the scalp
coupling index.

.. GENERATED FROM PYTHON SOURCE LINES 118-125

.. code-block:: default


    sci = mne.preprocessing.nirs.scalp_coupling_index(raw_od)
    fig, ax = plt.subplots()
    ax.hist(sci)
    ax.set(xlabel='Scalp Coupling Index', ylabel='Count', xlim=[0, 1])





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_004.png
   :alt: plot 15 waveform
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_004.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    [Text(0.5, 23.52222222222222, 'Scalp Coupling Index'), Text(47.097222222222214, 0.5, 'Count'), (0.0, 1.0)]



.. GENERATED FROM PYTHON SOURCE LINES 126-128

In this example we will mark all channels with a SCI less than 0.5 as bad
(this dataset is quite clean, so no channels are marked as bad).

.. GENERATED FROM PYTHON SOURCE LINES 128-132

.. code-block:: default


    raw_od.info['bads'] = list(compress(raw_od.ch_names, sci < 0.5))









.. GENERATED FROM PYTHON SOURCE LINES 133-139

At this stage it is appropriate to inspect your data
(for instructions on how to use the interactive data visualisation tool
see :ref:`tut-visualize-raw`)
to ensure that channels with poor scalp coupling have been removed.
If your data contains lots of artifacts you may decide to apply
artifact reduction techniques as described in :ref:`ex-fnirs-artifacts`.

.. GENERATED FROM PYTHON SOURCE LINES 142-147

Converting from optical density to haemoglobin
----------------------------------------------

Next we convert the optical density data to haemoglobin concentration using
the modified Beer-Lambert law.

.. GENERATED FROM PYTHON SOURCE LINES 147-153

.. code-block:: default


    raw_haemo = mne.preprocessing.nirs.beer_lambert_law(raw_od, ppf=0.1)
    raw_haemo.plot(n_channels=len(raw_haemo.ch_names),
                   duration=500, show_scrollbars=False)





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_005.png
   :alt: Raw plot
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_005.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <mne_qt_browser._pg_figure.MNEQtBrowser object at 0x7f104da58af0>



.. GENERATED FROM PYTHON SOURCE LINES 154-162

Removing heart rate from signal
-------------------------------

The haemodynamic response has frequency content predominantly below 0.5 Hz.
An increase in activity around 1 Hz can be seen in the data that is due to
the person's heart beat and is unwanted. So we use a low pass filter to
remove this. A high pass filter is also included to remove slow drifts
in the data.

.. GENERATED FROM PYTHON SOURCE LINES 162-172

.. code-block:: default


    fig = raw_haemo.plot_psd(average=True)
    fig.suptitle('Before filtering', weight='bold', size='x-large')
    fig.subplots_adjust(top=0.88)
    raw_haemo = raw_haemo.filter(0.05, 0.7, h_trans_bandwidth=0.2,
                                 l_trans_bandwidth=0.02)
    fig = raw_haemo.plot_psd(average=True)
    fig.suptitle('After filtering', weight='bold', size='x-large')
    fig.subplots_adjust(top=0.88)




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_006.png
         :alt: Before filtering, Oxyhemoglobin, Deoxyhemoglobin
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_006.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_007.png
         :alt: After filtering, Oxyhemoglobin, Deoxyhemoglobin
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_007.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    NOTE: plot_psd() is a legacy function. New code should use .compute_psd().plot().
    Effective window size : 32.768 (s)
    Filtering raw data in 1 contiguous segment
    Setting up band-pass filter from 0.05 - 0.7 Hz

    FIR filter parameters
    ---------------------
    Designing a one-pass, zero-phase, non-causal bandpass filter:
    - Windowed time-domain design (firwin) method
    - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation
    - Lower passband edge: 0.05
    - Lower transition bandwidth: 0.02 Hz (-6 dB cutoff frequency: 0.04 Hz)
    - Upper passband edge: 0.70 Hz
    - Upper transition bandwidth: 0.20 Hz (-6 dB cutoff frequency: 0.80 Hz)
    - Filter length: 1291 samples (165.248 sec)

    [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
    [Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
    [Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s
    [Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s
    [Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s
    [Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    0.1s finished
    NOTE: plot_psd() is a legacy function. New code should use .compute_psd().plot().
    Effective window size : 32.768 (s)




.. GENERATED FROM PYTHON SOURCE LINES 173-182

Extract epochs
--------------

Now that the signal has been converted to relative haemoglobin concentration,
and the unwanted heart rate component has been removed, we can extract epochs
related to each of the experimental conditions.

First we extract the events of interest and visualise them to ensure they are
correct.

.. GENERATED FROM PYTHON SOURCE LINES 182-189

.. code-block:: default


    events, event_dict = mne.events_from_annotations(raw_haemo)
    fig = mne.viz.plot_events(events, event_id=event_dict,
                              sfreq=raw_haemo.info['sfreq'])
    fig.subplots_adjust(right=0.7)  # make room for the legend





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_008.png
   :alt: plot 15 waveform
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_008.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Used Annotations descriptions: ['Control', 'Tapping/Left', 'Tapping/Right']




.. GENERATED FROM PYTHON SOURCE LINES 190-193

Next we define the range of our epochs, the rejection criteria,
baseline correction, and extract the epochs. We visualise the log of which
epochs were dropped.

.. GENERATED FROM PYTHON SOURCE LINES 193-205

.. code-block:: default


    reject_criteria = dict(hbo=80e-6)
    tmin, tmax = -5, 15

    epochs = mne.Epochs(raw_haemo, events, event_id=event_dict,
                        tmin=tmin, tmax=tmax,
                        reject=reject_criteria, reject_by_annotation=True,
                        proj=True, baseline=(None, 0), preload=True,
                        detrend=None, verbose=True)
    epochs.plot_drop_log()





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_009.png
   :alt: 6 of 90 epochs removed (6.7%)
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_009.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Not setting metadata
    90 matching events found
    Setting baseline interval to [-4.992, 0.0] sec
    Applying baseline correction (mode: mean)
    0 projection items activated
    Using data from preloaded Raw for 90 events and 157 original time points ...
        Rejecting  epoch based on HBO : ['S4_D4 hbo']
        Rejecting  epoch based on HBO : ['S4_D4 hbo', 'S8_D8 hbo']
        Rejecting  epoch based on HBO : ['S4_D4 hbo']
        Rejecting  epoch based on HBO : ['S4_D4 hbo', 'S8_D8 hbo']
        Rejecting  epoch based on HBO : ['S1_D1 hbo', 'S3_D3 hbo', 'S4_D4 hbo', 'S7_D6 hbo', 'S7_D7 hbo', 'S8_D8 hbo']
        Rejecting  epoch based on HBO : ['S4_D4 hbo', 'S6_D8 hbo', 'S8_D8 hbo']
    6 bad epochs dropped

    <Figure size 640x480 with 1 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 206-214

View consistency of responses across trials
-------------------------------------------

Now we can view the haemodynamic response for our tapping condition.
We visualise the response for both the oxy- and deoxyhaemoglobin, and
observe the expected peak in HbO at around 6 seconds consistently across
trials, and the consistent dip in HbR that is slightly delayed relative to
the HbO peak.

.. GENERATED FROM PYTHON SOURCE LINES 214-220

.. code-block:: default


    epochs['Tapping'].plot_image(combine='mean', vmin=-30, vmax=30,
                                 ts_args=dict(ylim=dict(hbo=[-15, 15],
                                                        hbr=[-15, 15])))





.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_010.png
         :alt: Oxyhemoglobin (mean)
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_010.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_011.png
         :alt: Deoxyhemoglobin (mean)
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_011.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Not setting metadata
    55 matching events found
    No baseline correction applied
    0 projection items activated
    Not setting metadata
    55 matching events found
    No baseline correction applied
    0 projection items activated
    combining channels using "mean"
    combining channels using "mean"

    [<Figure size 640x480 with 3 Axes>, <Figure size 640x480 with 3 Axes>]



.. GENERATED FROM PYTHON SOURCE LINES 221-223

We can also view the epoched data for the control condition and observe
that it does not show the expected morphology.

.. GENERATED FROM PYTHON SOURCE LINES 223-229

.. code-block:: default


    epochs['Control'].plot_image(combine='mean', vmin=-30, vmax=30,
                                 ts_args=dict(ylim=dict(hbo=[-15, 15],
                                                        hbr=[-15, 15])))





.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_012.png
         :alt: Oxyhemoglobin (mean)
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_012.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_013.png
         :alt: Deoxyhemoglobin (mean)
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_013.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Not setting metadata
    29 matching events found
    No baseline correction applied
    0 projection items activated
    Not setting metadata
    29 matching events found
    No baseline correction applied
    0 projection items activated
    combining channels using "mean"
    combining channels using "mean"

    [<Figure size 640x480 with 3 Axes>, <Figure size 640x480 with 3 Axes>]



.. GENERATED FROM PYTHON SOURCE LINES 230-236

View consistency of responses across channels
---------------------------------------------

Similarly we can view how consistent the response is across the optode
pairs that we selected. All the channels in this data are located over the
motor cortex, and all channels show a similar pattern in the data.

.. GENERATED FROM PYTHON SOURCE LINES 236-246

.. code-block:: default


    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 6))
    clims = dict(hbo=[-20, 20], hbr=[-20, 20])
    epochs['Control'].average().plot_image(axes=axes[:, 0], clim=clims)
    epochs['Tapping'].average().plot_image(axes=axes[:, 1], clim=clims)
    for column, condition in enumerate(['Control', 'Tapping']):
        for ax in axes[:, column]:
            ax.set_title('{}: {}'.format(condition, ax.get_title()))





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_014.png
   :alt: Control: Oxyhemoglobin (20 channels), Tapping: Oxyhemoglobin (20 channels), Control: Deoxyhemoglobin (20 channels), Tapping: Deoxyhemoglobin (20 channels), µM, µM, µM, µM
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_014.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 247-253

Plot standard fNIRS response image
----------------------------------

Next we generate the most common visualisation of fNIRS data: plotting
both the HbO and HbR on the same figure to illustrate the relation between
the two signals.

.. GENERATED FROM PYTHON SOURCE LINES 253-270

.. code-block:: default


    evoked_dict = {'Tapping/HbO': epochs['Tapping'].average(picks='hbo'),
                   'Tapping/HbR': epochs['Tapping'].average(picks='hbr'),
                   'Control/HbO': epochs['Control'].average(picks='hbo'),
                   'Control/HbR': epochs['Control'].average(picks='hbr')}

    # Rename channels until the encoding of frequency in ch_name is fixed
    for condition in evoked_dict:
        evoked_dict[condition].rename_channels(lambda x: x[:-4])

    color_dict = dict(HbO='#AA3377', HbR='b')
    styles_dict = dict(Control=dict(linestyle='dashed'))

    mne.viz.plot_compare_evokeds(evoked_dict, combine="mean", ci=0.95,
                                 colors=color_dict, styles=styles_dict)





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_015.png
   :alt: plot 15 waveform
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_015.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    combining channels using "mean"
    combining channels using "mean"
    combining channels using "mean"
    combining channels using "mean"

    [<Figure size 800x600 with 1 Axes>]



.. GENERATED FROM PYTHON SOURCE LINES 271-275

View topographic representation of activity
-------------------------------------------

Next we view how the topographic activity changes throughout the response.

.. GENERATED FROM PYTHON SOURCE LINES 275-282

.. code-block:: default


    times = np.arange(-3.5, 13.2, 3.0)
    topomap_args = dict(extrapolate='local')
    epochs['Tapping'].average(picks='hbo').plot_joint(
        times=times, topomap_args=topomap_args)





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_016.png
   :alt: -3.500 s, -0.500 s, 2.500 s, 5.500 s, 8.500 s, 11.500 s
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_016.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    No projector specified for this dataset. Please consider the method self.add_proj.

    <Figure size 800x420 with 10 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 283-288

Compare tapping of left and right hands
---------------------------------------

Finally we generate topo maps for the left and right conditions to view
the location of activity. First we visualise the HbO activity.

.. GENERATED FROM PYTHON SOURCE LINES 288-295

.. code-block:: default


    times = np.arange(4.0, 11.0, 1.0)
    epochs['Tapping/Left'].average(picks='hbo').plot_topomap(
        times=times, **topomap_args)
    epochs['Tapping/Right'].average(picks='hbo').plot_topomap(
        times=times, **topomap_args)




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_017.png
         :alt: 4.000 s, 5.000 s, 6.000 s, 7.000 s, 8.000 s, 9.000 s, 10.000 s, µM
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_017.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_018.png
         :alt: 4.000 s, 5.000 s, 6.000 s, 7.000 s, 8.000 s, 9.000 s, 10.000 s, µM
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_018.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <MNEFigure size 1200x220 with 8 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 296-297

And we also view the HbR activity for the two conditions.

.. GENERATED FROM PYTHON SOURCE LINES 297-303

.. code-block:: default


    epochs['Tapping/Left'].average(picks='hbr').plot_topomap(
        times=times, **topomap_args)
    epochs['Tapping/Right'].average(picks='hbr').plot_topomap(
        times=times, **topomap_args)




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_019.png
         :alt: 4.000 s, 5.000 s, 6.000 s, 7.000 s, 8.000 s, 9.000 s, 10.000 s, µM
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_019.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_020.png
         :alt: 4.000 s, 5.000 s, 6.000 s, 7.000 s, 8.000 s, 9.000 s, 10.000 s, µM
         :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_020.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <MNEFigure size 1200x220 with 8 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 304-305

And we can plot the comparison at a single time point for two conditions.

.. GENERATED FROM PYTHON SOURCE LINES 305-335

.. code-block:: default


    fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(9, 5),
                             gridspec_kw=dict(width_ratios=[1, 1, 1, 0.1]))
    vlim, ts = (-8, 8), 9.0

    evoked_left = epochs['Tapping/Left'].average()
    evoked_right = epochs['Tapping/Right'].average()

    evoked_left.plot_topomap(ch_type='hbo', times=ts, axes=axes[0, 0],
                             vlim=vlim, colorbar=False, **topomap_args)
    evoked_left.plot_topomap(ch_type='hbr', times=ts, axes=axes[1, 0],
                             vlim=vlim, colorbar=False, **topomap_args)
    evoked_right.plot_topomap(ch_type='hbo', times=ts, axes=axes[0, 1],
                              vlim=vlim, colorbar=False, **topomap_args)
    evoked_right.plot_topomap(ch_type='hbr', times=ts, axes=axes[1, 1],
                              vlim=vlim, colorbar=False, **topomap_args)

    evoked_diff = mne.combine_evoked([evoked_left, evoked_right], weights=[1, -1])

    evoked_diff.plot_topomap(ch_type='hbo', times=ts, axes=axes[0, 2:],
                             vlim=vlim, colorbar=True, **topomap_args)
    evoked_diff.plot_topomap(ch_type='hbr', times=ts, axes=axes[1, 2:],
                             vlim=vlim, colorbar=True, **topomap_args)

    for column, condition in enumerate(
            ['Tapping Left', 'Tapping Right', 'Left-Right']):
        for row, chroma in enumerate(['HbO', 'HbR']):
            axes[row, column].set_title('{}: {}'.format(chroma, condition))
    fig.tight_layout()




.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_021.png
   :alt: HbO: Tapping Left, HbO: Tapping Right, HbO: Left-Right, µM, HbR: Tapping Left, HbR: Tapping Right, HbR: Left-Right, µM
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_021.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 336-338

Lastly, we can also look at the individual waveforms to see what is
driving the topographic plot above.

.. GENERATED FROM PYTHON SOURCE LINES 338-349

.. code-block:: default


    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(6, 4))
    mne.viz.plot_evoked_topo(epochs['Left'].average(picks='hbo'), color='b',
                             axes=axes, legend=False)
    mne.viz.plot_evoked_topo(epochs['Right'].average(picks='hbo'), color='r',
                             axes=axes, legend=False)

    # Tidy the legend:
    leg_lines = [line for line in axes.lines if line.get_c() == 'b'][:1]
    leg_lines.append([line for line in axes.lines if line.get_c() == 'r'][0])
    fig.legend(leg_lines, ['Left', 'Right'], loc='lower right')



.. image-sg:: /auto_examples/general/images/sphx_glr_plot_15_waveform_022.png
   :alt: plot 15 waveform
   :srcset: /auto_examples/general/images/sphx_glr_plot_15_waveform_022.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <matplotlib.legend.Legend object at 0x7f104d133bb0>




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  23.289 seconds)

**Estimated memory usage:**  55 MB


.. _sphx_glr_download_auto_examples_general_plot_15_waveform.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/mne-tools/mne-nirs/gh-pages?filepath=stable/notebooks/auto_examples/general/plot_15_waveform.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_15_waveform.py <plot_15_waveform.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_15_waveform.ipynb <plot_15_waveform.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
